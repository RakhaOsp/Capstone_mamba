{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec370bd9-dfb5-4b70-ad80-4b6d38d5b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Monkey-patch MultiheadAttention so forward() returns only `attn_output`\n",
    "# -------------------------------------------------------------------------\n",
    "_original_mha_forward = nn.MultiheadAttention.forward\n",
    "\n",
    "def _mha_forward_no_weights(self, query, key, value, *args, **kwargs):\n",
    "    # call the original, then discard the weights\n",
    "    attn_output, _ = _original_mha_forward(self, query, key, value, *args, **kwargs)\n",
    "    return attn_output\n",
    "\n",
    "nn.MultiheadAttention.forward = _mha_forward_no_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62de866c-109e-468c-a9b1-5da1f5c059c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 22, 1000]             512\n",
      "       BatchNorm2d-2          [-1, 8, 22, 1000]              16\n",
      "            Conv2d-3         [-1, 256, 1, 1000]           5,632\n",
      "       BatchNorm2d-4         [-1, 256, 1, 1000]             512\n",
      "               ELU-5         [-1, 256, 1, 1000]               0\n",
      "         AvgPool2d-6          [-1, 256, 1, 125]               0\n",
      "           Dropout-7          [-1, 256, 1, 125]               0\n",
      "            Conv2d-8          [-1, 256, 1, 125]       1,048,576\n",
      "       BatchNorm2d-9          [-1, 256, 1, 125]             512\n",
      "              ELU-10          [-1, 256, 1, 125]               0\n",
      "        AvgPool2d-11           [-1, 256, 1, 15]               0\n",
      "          Dropout-12           [-1, 256, 1, 15]               0\n",
      "        Rearrange-13              [-1, 15, 256]               0\n",
      "PatchEmbeddingCNN-14              [-1, 15, 256]               0\n",
      "        LayerNorm-15              [-1, 15, 256]             512\n",
      "           Linear-16             [-1, 15, 1024]         262,144\n",
      "           Conv1d-17              [-1, 512, 18]           2,560\n",
      "           Linear-18              [-1, 15, 144]          73,728\n",
      "           Linear-19              [-1, 15, 512]           8,704\n",
      "           Linear-20              [-1, 15, 256]         131,072\n",
      "       MambaBlock-21              [-1, 15, 256]               0\n",
      "          Dropout-22              [-1, 15, 256]               0\n",
      "        LayerNorm-23              [-1, 15, 256]             512\n",
      "MultiheadAttention-24              [-1, 15, 256]               0\n",
      "          Dropout-25              [-1, 15, 256]               0\n",
      "        LayerNorm-26              [-1, 15, 256]             512\n",
      "           Linear-27             [-1, 15, 1024]         263,168\n",
      "             GELU-28             [-1, 15, 1024]               0\n",
      "          Dropout-29             [-1, 15, 1024]               0\n",
      "           Linear-30              [-1, 15, 256]         262,400\n",
      "          Dropout-31              [-1, 15, 256]               0\n",
      "        LayerNorm-32              [-1, 15, 256]             512\n",
      "MambaTransformerblock-33              [-1, 15, 256]               0\n",
      "          Flatten-34                 [-1, 3840]               0\n",
      "          Dropout-35                 [-1, 3840]               0\n",
      "           Linear-36                    [-1, 4]          15,364\n",
      "================================================================\n",
      "Total params: 2,076,948\n",
      "Trainable params: 2,076,948\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 10.91\n",
      "Params size (MB): 7.92\n",
      "Estimated Total Size (MB): 18.91\n",
      "----------------------------------------------------------------\n",
      "Tue Apr 29 12:37:32 2025\n",
      "seed is 258\n",
      "Subject 1\n",
      "Epoch 1/1000 | Train Loss: 1.2411 Acc: 0.4471 | Val Loss: 1.1549 Acc: 0.5233 | Mem: 2727.33MB | Speed: 210.49 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.9849 Acc: 0.5788 | Val Loss: 1.2936 Acc: 0.5116 | Mem: 2727.55MB | Speed: 219.02 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.7181 Acc: 0.7012 | Val Loss: 2.2353 Acc: 0.3605 | Mem: 2727.55MB | Speed: 220.00 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.5058 Acc: 0.8059 | Val Loss: 2.0420 Acc: 0.4884 | Mem: 2727.55MB | Speed: 220.04 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.3728 Acc: 0.8718 | Val Loss: 1.0542 Acc: 0.6279 | Mem: 2727.55MB | Speed: 221.54 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.3725 Acc: 0.8588 | Val Loss: 0.5747 Acc: 0.7558 | Mem: 2727.55MB | Speed: 220.66 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.3182 Acc: 0.8706 | Val Loss: 0.4546 Acc: 0.8256 | Mem: 2727.55MB | Speed: 219.06 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.2498 Acc: 0.8976 | Val Loss: 0.4104 Acc: 0.8256 | Mem: 2727.55MB | Speed: 218.60 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.2114 Acc: 0.9271 | Val Loss: 0.4601 Acc: 0.8256 | Mem: 2727.55MB | Speed: 219.23 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.2081 Acc: 0.9235 | Val Loss: 0.3517 Acc: 0.8488 | Mem: 2727.55MB | Speed: 219.64 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.1945 Acc: 0.9212 | Val Loss: 0.4075 Acc: 0.8488 | Mem: 2727.55MB | Speed: 219.26 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.1558 Acc: 0.9471 | Val Loss: 0.2803 Acc: 0.9070 | Mem: 2727.55MB | Speed: 217.94 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.1409 Acc: 0.9447 | Val Loss: 0.3117 Acc: 0.8721 | Mem: 2727.55MB | Speed: 218.51 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.1420 Acc: 0.9529 | Val Loss: 0.3167 Acc: 0.8837 | Mem: 2727.55MB | Speed: 218.51 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.1640 Acc: 0.9365 | Val Loss: 0.4143 Acc: 0.8488 | Mem: 2727.55MB | Speed: 218.11 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.1206 Acc: 0.9541 | Val Loss: 0.3216 Acc: 0.8721 | Mem: 2727.55MB | Speed: 217.46 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.1014 Acc: 0.9671 | Val Loss: 0.2090 Acc: 0.9070 | Mem: 2727.55MB | Speed: 218.29 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.1411 Acc: 0.9482 | Val Loss: 0.2411 Acc: 0.8953 | Mem: 2727.55MB | Speed: 215.06 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.0930 Acc: 0.9671 | Val Loss: 0.2060 Acc: 0.9419 | Mem: 2727.55MB | Speed: 216.20 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.1026 Acc: 0.9647 | Val Loss: 0.2321 Acc: 0.9070 | Mem: 2727.55MB | Speed: 217.14 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.0811 Acc: 0.9682 | Val Loss: 0.3139 Acc: 0.9070 | Mem: 2727.55MB | Speed: 218.45 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.0956 Acc: 0.9659 | Val Loss: 0.2207 Acc: 0.9302 | Mem: 2727.55MB | Speed: 218.22 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.0972 Acc: 0.9565 | Val Loss: 0.1689 Acc: 0.9070 | Mem: 2727.55MB | Speed: 217.76 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.1034 Acc: 0.9612 | Val Loss: 0.2730 Acc: 0.9419 | Mem: 2727.55MB | Speed: 217.17 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.1036 Acc: 0.9635 | Val Loss: 0.1923 Acc: 0.9651 | Mem: 2727.55MB | Speed: 218.03 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.0616 Acc: 0.9765 | Val Loss: 0.1156 Acc: 0.9535 | Mem: 2727.55MB | Speed: 217.06 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.0788 Acc: 0.9729 | Val Loss: 0.1362 Acc: 0.9535 | Mem: 2727.55MB | Speed: 216.82 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.0776 Acc: 0.9729 | Val Loss: 0.1212 Acc: 0.9651 | Mem: 2727.55MB | Speed: 216.95 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.0765 Acc: 0.9741 | Val Loss: 0.1375 Acc: 0.9767 | Mem: 2727.55MB | Speed: 217.84 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.0586 Acc: 0.9812 | Val Loss: 0.1455 Acc: 0.9419 | Mem: 2727.55MB | Speed: 215.87 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0649 Acc: 0.9765 | Val Loss: 0.1432 Acc: 0.9767 | Mem: 2727.55MB | Speed: 216.18 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.0913 Acc: 0.9694 | Val Loss: 0.1208 Acc: 0.9651 | Mem: 2727.55MB | Speed: 215.63 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0598 Acc: 0.9824 | Val Loss: 0.0319 Acc: 0.9767 | Mem: 2727.55MB | Speed: 217.22 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0708 Acc: 0.9753 | Val Loss: 0.0243 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.81 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0593 Acc: 0.9800 | Val Loss: 0.0873 Acc: 0.9535 | Mem: 2727.55MB | Speed: 217.08 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0466 Acc: 0.9871 | Val Loss: 0.0282 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.06 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0476 Acc: 0.9847 | Val Loss: 0.0756 Acc: 0.9651 | Mem: 2727.55MB | Speed: 216.25 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0388 Acc: 0.9894 | Val Loss: 0.1638 Acc: 0.9535 | Mem: 2727.55MB | Speed: 214.92 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0381 Acc: 0.9871 | Val Loss: 0.1122 Acc: 0.9419 | Mem: 2727.55MB | Speed: 216.28 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0461 Acc: 0.9824 | Val Loss: 0.0957 Acc: 0.9651 | Mem: 2727.55MB | Speed: 215.54 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0546 Acc: 0.9824 | Val Loss: 0.1039 Acc: 0.9651 | Mem: 2727.55MB | Speed: 216.66 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0430 Acc: 0.9906 | Val Loss: 0.1024 Acc: 0.9651 | Mem: 2727.55MB | Speed: 216.01 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0577 Acc: 0.9788 | Val Loss: 0.0467 Acc: 0.9767 | Mem: 2727.55MB | Speed: 216.03 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0391 Acc: 0.9906 | Val Loss: 0.0633 Acc: 0.9651 | Mem: 2727.55MB | Speed: 216.37 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0571 Acc: 0.9812 | Val Loss: 0.0793 Acc: 0.9651 | Mem: 2727.55MB | Speed: 216.45 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0368 Acc: 0.9894 | Val Loss: 0.0477 Acc: 0.9767 | Mem: 2727.55MB | Speed: 216.03 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0408 Acc: 0.9824 | Val Loss: 0.0176 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.75 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0521 Acc: 0.9824 | Val Loss: 0.0056 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.91 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0343 Acc: 0.9871 | Val Loss: 0.0126 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.26 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0454 Acc: 0.9894 | Val Loss: 0.0045 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.49 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0318 Acc: 0.9894 | Val Loss: 0.0051 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.73 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0353 Acc: 0.9894 | Val Loss: 0.0067 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.01 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0480 Acc: 0.9800 | Val Loss: 0.0019 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.97 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0314 Acc: 0.9871 | Val Loss: 0.0015 Acc: 1.0000 | Mem: 2727.55MB | Speed: 217.98 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0351 Acc: 0.9835 | Val Loss: 0.0029 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.77 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0376 Acc: 0.9812 | Val Loss: 0.0041 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.45 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0611 Acc: 0.9800 | Val Loss: 0.0139 Acc: 0.9884 | Mem: 2727.55MB | Speed: 213.60 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0339 Acc: 0.9906 | Val Loss: 0.0709 Acc: 0.9884 | Mem: 2727.55MB | Speed: 212.98 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0464 Acc: 0.9859 | Val Loss: 0.0157 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.39 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0701 Acc: 0.9765 | Val Loss: 0.0028 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.29 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0401 Acc: 0.9776 | Val Loss: 0.0072 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.51 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0422 Acc: 0.9847 | Val Loss: 0.0072 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.35 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0354 Acc: 0.9894 | Val Loss: 0.0081 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.07 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0484 Acc: 0.9847 | Val Loss: 0.0263 Acc: 0.9884 | Mem: 2727.55MB | Speed: 215.41 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0201 Acc: 0.9929 | Val Loss: 0.0203 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.34 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0367 Acc: 0.9894 | Val Loss: 0.0087 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.66 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0347 Acc: 0.9882 | Val Loss: 0.0189 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.84 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0340 Acc: 0.9918 | Val Loss: 0.0522 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.42 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0268 Acc: 0.9882 | Val Loss: 0.0031 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.00 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0388 Acc: 0.9847 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.55MB | Speed: 217.21 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0286 Acc: 0.9859 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.46 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0281 Acc: 0.9894 | Val Loss: 0.0008 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.09 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0273 Acc: 0.9906 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.69 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0275 Acc: 0.9929 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2727.55MB | Speed: 217.55 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0239 Acc: 0.9918 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.76 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0388 Acc: 0.9859 | Val Loss: 0.0053 Acc: 1.0000 | Mem: 2727.55MB | Speed: 217.87 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0295 Acc: 0.9894 | Val Loss: 0.0070 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.54 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0315 Acc: 0.9882 | Val Loss: 0.0264 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.13 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0445 Acc: 0.9882 | Val Loss: 0.0079 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.61 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0378 Acc: 0.9824 | Val Loss: 0.0028 Acc: 1.0000 | Mem: 2727.55MB | Speed: 217.47 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0299 Acc: 0.9894 | Val Loss: 0.0296 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.74 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0202 Acc: 0.9906 | Val Loss: 0.0298 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.47 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0217 Acc: 0.9929 | Val Loss: 0.0176 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.31 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0496 Acc: 0.9824 | Val Loss: 0.0234 Acc: 0.9884 | Mem: 2727.55MB | Speed: 215.42 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0206 Acc: 0.9918 | Val Loss: 0.0455 Acc: 0.9767 | Mem: 2727.55MB | Speed: 215.81 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0234 Acc: 0.9894 | Val Loss: 0.0273 Acc: 0.9884 | Mem: 2727.55MB | Speed: 215.59 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0341 Acc: 0.9894 | Val Loss: 0.0191 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.67 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0167 Acc: 0.9953 | Val Loss: 0.0692 Acc: 0.9767 | Mem: 2727.55MB | Speed: 217.13 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0323 Acc: 0.9941 | Val Loss: 0.0386 Acc: 0.9767 | Mem: 2727.55MB | Speed: 216.66 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0243 Acc: 0.9918 | Val Loss: 0.0445 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.04 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0451 Acc: 0.9835 | Val Loss: 0.0325 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.21 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0137 Acc: 0.9965 | Val Loss: 0.0721 Acc: 0.9651 | Mem: 2727.55MB | Speed: 215.31 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0336 Acc: 0.9882 | Val Loss: 0.0281 Acc: 0.9767 | Mem: 2727.55MB | Speed: 216.10 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0157 Acc: 0.9976 | Val Loss: 0.0067 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.18 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0228 Acc: 0.9906 | Val Loss: 0.0040 Acc: 1.0000 | Mem: 2727.55MB | Speed: 217.51 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0270 Acc: 0.9882 | Val Loss: 0.0165 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.85 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0246 Acc: 0.9906 | Val Loss: 0.0298 Acc: 0.9767 | Mem: 2727.55MB | Speed: 215.71 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0202 Acc: 0.9929 | Val Loss: 0.0318 Acc: 0.9884 | Mem: 2727.55MB | Speed: 215.42 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0271 Acc: 0.9906 | Val Loss: 0.0334 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.43 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0247 Acc: 0.9894 | Val Loss: 0.0099 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.64 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0299 Acc: 0.9906 | Val Loss: 0.0365 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.70 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0245 Acc: 0.9906 | Val Loss: 0.0090 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.87 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0229 Acc: 0.9906 | Val Loss: 0.0082 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.79 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0269 Acc: 0.9882 | Val Loss: 0.0180 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.20 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0239 Acc: 0.9871 | Val Loss: 0.0023 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.05 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0158 Acc: 0.9965 | Val Loss: 0.0038 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.70 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0224 Acc: 0.9918 | Val Loss: 0.0358 Acc: 0.9884 | Mem: 2727.55MB | Speed: 216.94 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0273 Acc: 0.9918 | Val Loss: 0.0146 Acc: 0.9884 | Mem: 2727.55MB | Speed: 217.68 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0145 Acc: 0.9929 | Val Loss: 0.0042 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.49 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0253 Acc: 0.9906 | Val Loss: 0.0031 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.77 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0246 Acc: 0.9941 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.71 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0297 Acc: 0.9894 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.04 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0264 Acc: 0.9882 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.85 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0281 Acc: 0.9894 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.99 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0280 Acc: 0.9847 | Val Loss: 0.0019 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.61 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0095 Acc: 0.9976 | Val Loss: 0.0032 Acc: 1.0000 | Mem: 2727.55MB | Speed: 218.26 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0241 Acc: 0.9941 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.49 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0140 Acc: 0.9953 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.73 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0254 Acc: 0.9929 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.92 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0312 Acc: 0.9894 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.52 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0212 Acc: 0.9929 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2727.55MB | Speed: 216.08 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0279 Acc: 0.9929 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.63 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0360 Acc: 0.9906 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2727.55MB | Speed: 215.88 samples/s\n",
      "Stopping early at epoch 123 (no improvement in 100 epochs).\n",
      "Subject 1 final accuracy: 0.7847\n",
      "seed is 397\n",
      "Subject 2\n",
      "Epoch 1/1000 | Train Loss: 1.3486 Acc: 0.4035 | Val Loss: 1.0267 Acc: 0.6163 | Mem: 2737.73MB | Speed: 216.26 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.9997 Acc: 0.5882 | Val Loss: 0.9505 Acc: 0.6163 | Mem: 2738.14MB | Speed: 216.89 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.8147 Acc: 0.6635 | Val Loss: 0.7524 Acc: 0.6977 | Mem: 2738.14MB | Speed: 216.13 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.7062 Acc: 0.7176 | Val Loss: 0.6519 Acc: 0.7326 | Mem: 2738.14MB | Speed: 216.93 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.6051 Acc: 0.7635 | Val Loss: 0.6175 Acc: 0.7442 | Mem: 2738.14MB | Speed: 216.29 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.5311 Acc: 0.7824 | Val Loss: 0.5265 Acc: 0.8488 | Mem: 2738.14MB | Speed: 216.48 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.4597 Acc: 0.8306 | Val Loss: 0.5041 Acc: 0.8372 | Mem: 2727.93MB | Speed: 217.18 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.4263 Acc: 0.8306 | Val Loss: 0.4628 Acc: 0.8256 | Mem: 2727.88MB | Speed: 216.68 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.3807 Acc: 0.8565 | Val Loss: 0.3644 Acc: 0.8837 | Mem: 2728.15MB | Speed: 216.14 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.3677 Acc: 0.8718 | Val Loss: 0.3993 Acc: 0.8372 | Mem: 2728.02MB | Speed: 216.69 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.3625 Acc: 0.8624 | Val Loss: 0.3595 Acc: 0.8837 | Mem: 2728.54MB | Speed: 217.25 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.2972 Acc: 0.9047 | Val Loss: 0.2958 Acc: 0.8837 | Mem: 2727.71MB | Speed: 215.86 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.2748 Acc: 0.9024 | Val Loss: 0.2540 Acc: 0.9070 | Mem: 2727.38MB | Speed: 216.53 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.2649 Acc: 0.9047 | Val Loss: 0.2184 Acc: 0.8953 | Mem: 2727.38MB | Speed: 216.47 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.2760 Acc: 0.8988 | Val Loss: 0.2348 Acc: 0.8837 | Mem: 2727.38MB | Speed: 216.98 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.2247 Acc: 0.9282 | Val Loss: 0.2387 Acc: 0.8721 | Mem: 2727.38MB | Speed: 215.66 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.2232 Acc: 0.9235 | Val Loss: 0.2486 Acc: 0.8721 | Mem: 2727.38MB | Speed: 216.35 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.2226 Acc: 0.9188 | Val Loss: 0.2751 Acc: 0.8953 | Mem: 2727.38MB | Speed: 217.61 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.2072 Acc: 0.9329 | Val Loss: 0.2460 Acc: 0.9070 | Mem: 2727.38MB | Speed: 217.14 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.1757 Acc: 0.9412 | Val Loss: 0.1756 Acc: 0.9302 | Mem: 2727.38MB | Speed: 215.94 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.1985 Acc: 0.9306 | Val Loss: 0.2170 Acc: 0.9186 | Mem: 2727.38MB | Speed: 214.80 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.1971 Acc: 0.9259 | Val Loss: 0.1768 Acc: 0.9302 | Mem: 2727.38MB | Speed: 215.67 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.1467 Acc: 0.9471 | Val Loss: 0.1308 Acc: 0.9419 | Mem: 2727.38MB | Speed: 215.89 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.1864 Acc: 0.9353 | Val Loss: 0.1855 Acc: 0.9302 | Mem: 2727.38MB | Speed: 215.81 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.1468 Acc: 0.9494 | Val Loss: 0.1270 Acc: 0.9535 | Mem: 2727.38MB | Speed: 216.06 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.1074 Acc: 0.9612 | Val Loss: 0.1034 Acc: 0.9302 | Mem: 2727.38MB | Speed: 216.03 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.1528 Acc: 0.9459 | Val Loss: 0.1072 Acc: 0.9535 | Mem: 2727.38MB | Speed: 215.87 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.1495 Acc: 0.9412 | Val Loss: 0.0956 Acc: 0.9651 | Mem: 2727.38MB | Speed: 215.61 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.1354 Acc: 0.9518 | Val Loss: 0.1190 Acc: 0.9651 | Mem: 2727.38MB | Speed: 215.36 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.1058 Acc: 0.9576 | Val Loss: 0.1389 Acc: 0.9535 | Mem: 2727.38MB | Speed: 216.77 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.1229 Acc: 0.9565 | Val Loss: 0.1278 Acc: 0.9651 | Mem: 2727.38MB | Speed: 215.93 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.1275 Acc: 0.9588 | Val Loss: 0.1107 Acc: 0.9651 | Mem: 2727.38MB | Speed: 215.75 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.1382 Acc: 0.9494 | Val Loss: 0.0928 Acc: 0.9767 | Mem: 2727.38MB | Speed: 215.57 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.1318 Acc: 0.9576 | Val Loss: 0.1218 Acc: 0.9651 | Mem: 2727.38MB | Speed: 215.44 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.1275 Acc: 0.9553 | Val Loss: 0.0894 Acc: 0.9767 | Mem: 2727.38MB | Speed: 215.98 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.1104 Acc: 0.9600 | Val Loss: 0.0518 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.85 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.1021 Acc: 0.9718 | Val Loss: 0.0540 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.38 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.1028 Acc: 0.9706 | Val Loss: 0.0534 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.27 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0957 Acc: 0.9659 | Val Loss: 0.0357 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.25 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0805 Acc: 0.9765 | Val Loss: 0.0495 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.87 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0921 Acc: 0.9612 | Val Loss: 0.0770 Acc: 0.9651 | Mem: 2727.38MB | Speed: 217.38 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0891 Acc: 0.9682 | Val Loss: 0.0783 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.70 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0818 Acc: 0.9741 | Val Loss: 0.0199 Acc: 0.9884 | Mem: 2727.38MB | Speed: 215.70 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0883 Acc: 0.9659 | Val Loss: 0.0096 Acc: 1.0000 | Mem: 2727.38MB | Speed: 215.22 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0854 Acc: 0.9718 | Val Loss: 0.0333 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.68 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.1016 Acc: 0.9647 | Val Loss: 0.0232 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.03 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0646 Acc: 0.9753 | Val Loss: 0.0081 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.88 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.1081 Acc: 0.9576 | Val Loss: 0.0481 Acc: 0.9767 | Mem: 2727.38MB | Speed: 217.10 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0776 Acc: 0.9718 | Val Loss: 0.0158 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.46 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0627 Acc: 0.9788 | Val Loss: 0.0142 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.59 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0861 Acc: 0.9706 | Val Loss: 0.0377 Acc: 0.9767 | Mem: 2727.38MB | Speed: 215.75 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0760 Acc: 0.9741 | Val Loss: 0.0494 Acc: 0.9767 | Mem: 2727.38MB | Speed: 215.21 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0618 Acc: 0.9812 | Val Loss: 0.0335 Acc: 0.9884 | Mem: 2727.38MB | Speed: 215.45 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0623 Acc: 0.9800 | Val Loss: 0.0273 Acc: 0.9884 | Mem: 2727.38MB | Speed: 215.81 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0489 Acc: 0.9824 | Val Loss: 0.0441 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.64 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0764 Acc: 0.9765 | Val Loss: 0.0190 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.69 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0616 Acc: 0.9776 | Val Loss: 0.0259 Acc: 0.9884 | Mem: 2727.38MB | Speed: 215.94 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0846 Acc: 0.9753 | Val Loss: 0.0349 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.44 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0651 Acc: 0.9788 | Val Loss: 0.0065 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.23 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0581 Acc: 0.9812 | Val Loss: 0.0130 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.10 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0488 Acc: 0.9824 | Val Loss: 0.0052 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.58 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0696 Acc: 0.9824 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.32 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0615 Acc: 0.9776 | Val Loss: 0.0120 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.87 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0543 Acc: 0.9800 | Val Loss: 0.0047 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.66 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0497 Acc: 0.9847 | Val Loss: 0.0389 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.75 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0421 Acc: 0.9835 | Val Loss: 0.0071 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.66 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0627 Acc: 0.9753 | Val Loss: 0.0068 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.64 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0525 Acc: 0.9788 | Val Loss: 0.0419 Acc: 0.9767 | Mem: 2727.38MB | Speed: 217.69 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0706 Acc: 0.9729 | Val Loss: 0.0587 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.25 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0768 Acc: 0.9706 | Val Loss: 0.0398 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.69 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0638 Acc: 0.9788 | Val Loss: 0.0184 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.80 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0528 Acc: 0.9824 | Val Loss: 0.0650 Acc: 0.9767 | Mem: 2727.38MB | Speed: 216.62 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0599 Acc: 0.9765 | Val Loss: 0.0499 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.27 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0434 Acc: 0.9871 | Val Loss: 0.0152 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.03 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0534 Acc: 0.9788 | Val Loss: 0.0373 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.31 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0636 Acc: 0.9753 | Val Loss: 0.0207 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.00 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0349 Acc: 0.9871 | Val Loss: 0.0018 Acc: 1.0000 | Mem: 2727.38MB | Speed: 218.53 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0361 Acc: 0.9882 | Val Loss: 0.0019 Acc: 1.0000 | Mem: 2727.38MB | Speed: 218.21 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0589 Acc: 0.9835 | Val Loss: 0.0023 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.59 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0568 Acc: 0.9835 | Val Loss: 0.0024 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.52 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0308 Acc: 0.9918 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2727.38MB | Speed: 218.15 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0333 Acc: 0.9882 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.59 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0259 Acc: 0.9918 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.92 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0283 Acc: 0.9906 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.21 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0419 Acc: 0.9835 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.82 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0396 Acc: 0.9812 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.93 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0349 Acc: 0.9906 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.61 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0335 Acc: 0.9871 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.06 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0441 Acc: 0.9847 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2727.38MB | Speed: 215.89 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0336 Acc: 0.9894 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.68 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0378 Acc: 0.9871 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.13 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0417 Acc: 0.9835 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.15 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0448 Acc: 0.9800 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.42 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0376 Acc: 0.9871 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.03 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0294 Acc: 0.9882 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.77 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0545 Acc: 0.9800 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.22 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0363 Acc: 0.9859 | Val Loss: 0.0069 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.35 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0295 Acc: 0.9882 | Val Loss: 0.0083 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.96 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0235 Acc: 0.9929 | Val Loss: 0.0036 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.77 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0303 Acc: 0.9929 | Val Loss: 0.0010 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.42 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0525 Acc: 0.9882 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.06 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0273 Acc: 0.9918 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.48 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0358 Acc: 0.9847 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.28 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0424 Acc: 0.9871 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 215.71 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0218 Acc: 0.9941 | Val Loss: 0.0067 Acc: 0.9884 | Mem: 2727.38MB | Speed: 217.20 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0272 Acc: 0.9882 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.95 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0311 Acc: 0.9882 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.13 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0459 Acc: 0.9824 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.84 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0144 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.54 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0320 Acc: 0.9882 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.85 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0604 Acc: 0.9776 | Val Loss: 0.0041 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.31 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0348 Acc: 0.9882 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.09 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0368 Acc: 0.9824 | Val Loss: 0.0011 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.36 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0267 Acc: 0.9894 | Val Loss: 0.0074 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.62 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0359 Acc: 0.9894 | Val Loss: 0.0096 Acc: 0.9884 | Mem: 2727.38MB | Speed: 216.94 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0186 Acc: 0.9929 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.98 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0443 Acc: 0.9859 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.38 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0382 Acc: 0.9859 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 215.43 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0369 Acc: 0.9918 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.25 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0289 Acc: 0.9882 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.69 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0461 Acc: 0.9847 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.49 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0293 Acc: 0.9929 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.43 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0611 Acc: 0.9800 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.63 samples/s\n",
      "Epoch 124/1000 | Train Loss: 0.0267 Acc: 0.9929 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.47 samples/s\n",
      "Epoch 125/1000 | Train Loss: 0.0308 Acc: 0.9882 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.53 samples/s\n",
      "Epoch 126/1000 | Train Loss: 0.0368 Acc: 0.9871 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.21 samples/s\n",
      "Epoch 127/1000 | Train Loss: 0.0524 Acc: 0.9812 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.60 samples/s\n",
      "Epoch 128/1000 | Train Loss: 0.0348 Acc: 0.9906 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.92 samples/s\n",
      "Epoch 129/1000 | Train Loss: 0.0190 Acc: 0.9941 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.10 samples/s\n",
      "Epoch 130/1000 | Train Loss: 0.0290 Acc: 0.9871 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.22 samples/s\n",
      "Epoch 131/1000 | Train Loss: 0.0218 Acc: 0.9918 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.94 samples/s\n",
      "Epoch 132/1000 | Train Loss: 0.0225 Acc: 0.9906 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.86 samples/s\n",
      "Epoch 133/1000 | Train Loss: 0.0189 Acc: 0.9941 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 216.54 samples/s\n",
      "Epoch 134/1000 | Train Loss: 0.0430 Acc: 0.9882 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 215.81 samples/s\n",
      "Epoch 135/1000 | Train Loss: 0.0150 Acc: 0.9918 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.82 samples/s\n",
      "Epoch 136/1000 | Train Loss: 0.0239 Acc: 0.9882 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.67 samples/s\n",
      "Epoch 137/1000 | Train Loss: 0.0335 Acc: 0.9835 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2727.38MB | Speed: 217.43 samples/s\n",
      "Stopping early at epoch 137 (no improvement in 100 epochs).\n",
      "Subject 2 final accuracy: 0.5799\n",
      "seed is 696\n",
      "Subject 3\n",
      "Epoch 1/1000 | Train Loss: 1.2337 Acc: 0.4412 | Val Loss: 1.0225 Acc: 0.6395 | Mem: 2737.19MB | Speed: 216.00 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.8085 Acc: 0.6494 | Val Loss: 1.5333 Acc: 0.5698 | Mem: 2737.19MB | Speed: 216.61 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.6196 Acc: 0.7541 | Val Loss: 1.9797 Acc: 0.5698 | Mem: 2736.97MB | Speed: 216.65 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.4638 Acc: 0.8424 | Val Loss: 1.7221 Acc: 0.6163 | Mem: 2737.19MB | Speed: 215.20 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.4190 Acc: 0.8541 | Val Loss: 1.4332 Acc: 0.7093 | Mem: 2736.97MB | Speed: 216.12 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.2951 Acc: 0.8906 | Val Loss: 0.7958 Acc: 0.7674 | Mem: 2737.19MB | Speed: 216.46 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.2996 Acc: 0.8882 | Val Loss: 0.4869 Acc: 0.8372 | Mem: 2736.97MB | Speed: 216.45 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.1936 Acc: 0.9412 | Val Loss: 0.3467 Acc: 0.8721 | Mem: 2737.19MB | Speed: 216.65 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.1881 Acc: 0.9318 | Val Loss: 0.2401 Acc: 0.8837 | Mem: 2736.97MB | Speed: 216.63 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.1682 Acc: 0.9435 | Val Loss: 0.1530 Acc: 0.9419 | Mem: 2737.19MB | Speed: 215.40 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.1711 Acc: 0.9400 | Val Loss: 0.1534 Acc: 0.9535 | Mem: 2736.97MB | Speed: 216.07 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.1454 Acc: 0.9494 | Val Loss: 0.1476 Acc: 0.9651 | Mem: 2737.19MB | Speed: 215.63 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.1163 Acc: 0.9576 | Val Loss: 0.1262 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.11 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.1125 Acc: 0.9600 | Val Loss: 0.1052 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.19 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.0922 Acc: 0.9624 | Val Loss: 0.1426 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.80 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.0913 Acc: 0.9741 | Val Loss: 0.1344 Acc: 0.9651 | Mem: 2737.19MB | Speed: 215.97 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.0863 Acc: 0.9718 | Val Loss: 0.1030 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.30 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.0793 Acc: 0.9765 | Val Loss: 0.1376 Acc: 0.9651 | Mem: 2737.19MB | Speed: 216.24 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.0828 Acc: 0.9776 | Val Loss: 0.1685 Acc: 0.9651 | Mem: 2736.97MB | Speed: 215.36 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.0627 Acc: 0.9800 | Val Loss: 0.1798 Acc: 0.9535 | Mem: 2737.19MB | Speed: 216.11 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.0672 Acc: 0.9776 | Val Loss: 0.1495 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.28 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.0813 Acc: 0.9718 | Val Loss: 0.1501 Acc: 0.9767 | Mem: 2737.19MB | Speed: 215.78 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.0752 Acc: 0.9729 | Val Loss: 0.1371 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.07 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.0622 Acc: 0.9788 | Val Loss: 0.1034 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.43 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.0539 Acc: 0.9824 | Val Loss: 0.0912 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.29 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.0534 Acc: 0.9835 | Val Loss: 0.1229 Acc: 0.9767 | Mem: 2737.19MB | Speed: 215.70 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.0492 Acc: 0.9835 | Val Loss: 0.1047 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.60 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.0604 Acc: 0.9824 | Val Loss: 0.0947 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.97 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.0571 Acc: 0.9812 | Val Loss: 0.1011 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.49 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.0356 Acc: 0.9906 | Val Loss: 0.1106 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.51 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0631 Acc: 0.9800 | Val Loss: 0.0834 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.60 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.0452 Acc: 0.9835 | Val Loss: 0.0695 Acc: 0.9767 | Mem: 2737.19MB | Speed: 215.57 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0483 Acc: 0.9824 | Val Loss: 0.0695 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.44 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0331 Acc: 0.9882 | Val Loss: 0.0828 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.21 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0437 Acc: 0.9882 | Val Loss: 0.0806 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.12 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0365 Acc: 0.9882 | Val Loss: 0.0908 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.36 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0488 Acc: 0.9847 | Val Loss: 0.1335 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.43 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0357 Acc: 0.9929 | Val Loss: 0.1595 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.79 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0341 Acc: 0.9882 | Val Loss: 0.1217 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.19 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0397 Acc: 0.9871 | Val Loss: 0.1735 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.83 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0482 Acc: 0.9859 | Val Loss: 0.1993 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.09 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0186 Acc: 0.9953 | Val Loss: 0.1458 Acc: 0.9767 | Mem: 2737.19MB | Speed: 215.53 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0451 Acc: 0.9835 | Val Loss: 0.1527 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.77 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0400 Acc: 0.9871 | Val Loss: 0.0779 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.50 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0447 Acc: 0.9835 | Val Loss: 0.1056 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.30 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0356 Acc: 0.9824 | Val Loss: 0.1368 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.80 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0274 Acc: 0.9906 | Val Loss: 0.1180 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.15 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0443 Acc: 0.9800 | Val Loss: 0.0885 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.51 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0318 Acc: 0.9847 | Val Loss: 0.0792 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.19 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0402 Acc: 0.9824 | Val Loss: 0.0616 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.47 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0302 Acc: 0.9882 | Val Loss: 0.0493 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.69 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0257 Acc: 0.9918 | Val Loss: 0.0750 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.68 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0407 Acc: 0.9871 | Val Loss: 0.1265 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.78 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0306 Acc: 0.9859 | Val Loss: 0.0956 Acc: 0.9884 | Mem: 2737.19MB | Speed: 217.37 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0256 Acc: 0.9918 | Val Loss: 0.0541 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.69 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0230 Acc: 0.9929 | Val Loss: 0.0237 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.20 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0337 Acc: 0.9871 | Val Loss: 0.0119 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.02 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0296 Acc: 0.9894 | Val Loss: 0.0061 Acc: 1.0000 | Mem: 2737.19MB | Speed: 215.16 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0212 Acc: 0.9918 | Val Loss: 0.0015 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.10 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0199 Acc: 0.9941 | Val Loss: 0.0033 Acc: 1.0000 | Mem: 2737.19MB | Speed: 216.26 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0222 Acc: 0.9918 | Val Loss: 0.0044 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.84 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0266 Acc: 0.9918 | Val Loss: 0.0057 Acc: 1.0000 | Mem: 2737.19MB | Speed: 216.78 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0417 Acc: 0.9788 | Val Loss: 0.0044 Acc: 1.0000 | Mem: 2736.97MB | Speed: 217.63 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0167 Acc: 0.9965 | Val Loss: 0.0014 Acc: 1.0000 | Mem: 2737.19MB | Speed: 215.87 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0182 Acc: 0.9953 | Val Loss: 0.0038 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.55 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0187 Acc: 0.9965 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2737.19MB | Speed: 216.95 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0230 Acc: 0.9894 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.05 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0173 Acc: 0.9929 | Val Loss: 0.0071 Acc: 1.0000 | Mem: 2737.19MB | Speed: 216.31 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0249 Acc: 0.9906 | Val Loss: 0.0082 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.81 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0147 Acc: 0.9965 | Val Loss: 0.0073 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.42 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0109 Acc: 0.9988 | Val Loss: 0.0040 Acc: 1.0000 | Mem: 2736.97MB | Speed: 215.98 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0242 Acc: 0.9929 | Val Loss: 0.0045 Acc: 1.0000 | Mem: 2737.19MB | Speed: 215.82 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0272 Acc: 0.9894 | Val Loss: 0.0250 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.08 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0482 Acc: 0.9847 | Val Loss: 0.0611 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.48 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0209 Acc: 0.9918 | Val Loss: 0.0024 Acc: 1.0000 | Mem: 2736.97MB | Speed: 217.64 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0260 Acc: 0.9906 | Val Loss: 0.0317 Acc: 0.9884 | Mem: 2737.19MB | Speed: 217.05 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0312 Acc: 0.9918 | Val Loss: 0.0129 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.47 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0465 Acc: 0.9835 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2737.19MB | Speed: 216.28 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0253 Acc: 0.9906 | Val Loss: 0.0043 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.12 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0292 Acc: 0.9894 | Val Loss: 0.0212 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.26 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0225 Acc: 0.9918 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.14 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0141 Acc: 0.9965 | Val Loss: 0.0035 Acc: 1.0000 | Mem: 2737.19MB | Speed: 215.69 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0197 Acc: 0.9953 | Val Loss: 0.0228 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.37 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0218 Acc: 0.9918 | Val Loss: 0.0125 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.81 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0331 Acc: 0.9847 | Val Loss: 0.0119 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.66 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0195 Acc: 0.9929 | Val Loss: 0.0431 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.61 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0360 Acc: 0.9871 | Val Loss: 0.0089 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.56 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0173 Acc: 0.9953 | Val Loss: 0.0085 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.88 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0163 Acc: 0.9965 | Val Loss: 0.0024 Acc: 1.0000 | Mem: 2736.97MB | Speed: 217.18 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0143 Acc: 0.9941 | Val Loss: 0.0149 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.45 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0332 Acc: 0.9894 | Val Loss: 0.0040 Acc: 1.0000 | Mem: 2736.97MB | Speed: 217.13 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0129 Acc: 0.9965 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2737.19MB | Speed: 216.58 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0202 Acc: 0.9929 | Val Loss: 0.0496 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.52 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0281 Acc: 0.9882 | Val Loss: 0.0967 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.87 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0083 Acc: 0.9976 | Val Loss: 0.0702 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.98 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0240 Acc: 0.9918 | Val Loss: 0.0708 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.26 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0407 Acc: 0.9882 | Val Loss: 0.0927 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.91 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0269 Acc: 0.9906 | Val Loss: 0.0282 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.50 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0177 Acc: 0.9965 | Val Loss: 0.0036 Acc: 1.0000 | Mem: 2736.97MB | Speed: 216.39 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0182 Acc: 0.9929 | Val Loss: 0.0281 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.91 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0294 Acc: 0.9906 | Val Loss: 0.0543 Acc: 0.9884 | Mem: 2736.97MB | Speed: 215.80 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0243 Acc: 0.9882 | Val Loss: 0.0550 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.78 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0196 Acc: 0.9941 | Val Loss: 0.0320 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.17 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0185 Acc: 0.9941 | Val Loss: 0.0430 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.83 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0166 Acc: 0.9965 | Val Loss: 0.0240 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.28 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0217 Acc: 0.9918 | Val Loss: 0.0449 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.57 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0346 Acc: 0.9882 | Val Loss: 0.0579 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.65 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0202 Acc: 0.9929 | Val Loss: 0.0671 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.27 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0215 Acc: 0.9929 | Val Loss: 0.1516 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.01 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0247 Acc: 0.9918 | Val Loss: 0.1543 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.75 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0158 Acc: 0.9941 | Val Loss: 0.1070 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.77 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0220 Acc: 0.9941 | Val Loss: 0.1250 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.14 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0128 Acc: 0.9953 | Val Loss: 0.0815 Acc: 0.9767 | Mem: 2736.97MB | Speed: 215.73 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0196 Acc: 0.9941 | Val Loss: 0.0334 Acc: 0.9884 | Mem: 2737.19MB | Speed: 215.43 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0205 Acc: 0.9941 | Val Loss: 0.0207 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.69 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0179 Acc: 0.9941 | Val Loss: 0.0155 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.61 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0202 Acc: 0.9941 | Val Loss: 0.0168 Acc: 0.9884 | Mem: 2736.97MB | Speed: 216.45 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0095 Acc: 0.9965 | Val Loss: 0.0180 Acc: 0.9884 | Mem: 2737.19MB | Speed: 216.70 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0108 Acc: 0.9976 | Val Loss: 0.0391 Acc: 0.9767 | Mem: 2736.97MB | Speed: 216.17 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0113 Acc: 0.9953 | Val Loss: 0.0733 Acc: 0.9767 | Mem: 2737.19MB | Speed: 216.20 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0184 Acc: 0.9953 | Val Loss: 0.0244 Acc: 0.9884 | Mem: 2736.97MB | Speed: 217.69 samples/s\n",
      "Stopping early at epoch 121 (no improvement in 100 epochs).\n",
      "Subject 3 final accuracy: 0.9271\n",
      "seed is 53\n",
      "Subject 4\n",
      "Epoch 1/1000 | Train Loss: 1.3179 Acc: 0.4094 | Val Loss: 1.3125 Acc: 0.4419 | Mem: 2745.52MB | Speed: 217.96 samples/s\n",
      "Epoch 2/1000 | Train Loss: 1.0934 Acc: 0.5329 | Val Loss: 1.0359 Acc: 0.5465 | Mem: 2745.52MB | Speed: 216.99 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.9016 Acc: 0.6318 | Val Loss: 0.8778 Acc: 0.6395 | Mem: 2745.52MB | Speed: 215.59 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.7412 Acc: 0.7047 | Val Loss: 0.7889 Acc: 0.7093 | Mem: 2745.52MB | Speed: 215.86 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.6049 Acc: 0.7765 | Val Loss: 0.6986 Acc: 0.7558 | Mem: 2745.52MB | Speed: 216.37 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.5176 Acc: 0.7941 | Val Loss: 0.6216 Acc: 0.8140 | Mem: 2745.52MB | Speed: 216.98 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.4408 Acc: 0.8306 | Val Loss: 0.4514 Acc: 0.8605 | Mem: 2745.52MB | Speed: 216.46 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.4060 Acc: 0.8482 | Val Loss: 0.4854 Acc: 0.8256 | Mem: 2745.52MB | Speed: 216.52 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.4045 Acc: 0.8459 | Val Loss: 0.3490 Acc: 0.8721 | Mem: 2745.52MB | Speed: 216.71 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.3262 Acc: 0.8694 | Val Loss: 0.3111 Acc: 0.9070 | Mem: 2745.52MB | Speed: 216.85 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.3220 Acc: 0.8800 | Val Loss: 0.3342 Acc: 0.8837 | Mem: 2745.52MB | Speed: 216.63 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.2847 Acc: 0.9059 | Val Loss: 0.2658 Acc: 0.9302 | Mem: 2745.52MB | Speed: 216.39 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.2500 Acc: 0.9082 | Val Loss: 0.2188 Acc: 0.9419 | Mem: 2745.52MB | Speed: 217.32 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.2540 Acc: 0.9094 | Val Loss: 0.2330 Acc: 0.9302 | Mem: 2745.52MB | Speed: 216.71 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.2239 Acc: 0.9224 | Val Loss: 0.2143 Acc: 0.9186 | Mem: 2745.52MB | Speed: 217.03 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.2175 Acc: 0.9294 | Val Loss: 0.2182 Acc: 0.9186 | Mem: 2745.52MB | Speed: 217.49 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.1655 Acc: 0.9412 | Val Loss: 0.1974 Acc: 0.9186 | Mem: 2745.52MB | Speed: 216.90 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.1817 Acc: 0.9376 | Val Loss: 0.2253 Acc: 0.9419 | Mem: 2745.52MB | Speed: 216.32 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.1582 Acc: 0.9494 | Val Loss: 0.1433 Acc: 0.9651 | Mem: 2745.52MB | Speed: 216.55 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.1666 Acc: 0.9424 | Val Loss: 0.1744 Acc: 0.9302 | Mem: 2745.52MB | Speed: 216.95 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.1391 Acc: 0.9459 | Val Loss: 0.1171 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.46 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.1373 Acc: 0.9576 | Val Loss: 0.1439 Acc: 0.9535 | Mem: 2745.52MB | Speed: 216.82 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.1216 Acc: 0.9588 | Val Loss: 0.1190 Acc: 0.9651 | Mem: 2745.52MB | Speed: 217.91 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.1211 Acc: 0.9565 | Val Loss: 0.0785 Acc: 0.9651 | Mem: 2745.52MB | Speed: 216.82 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.1273 Acc: 0.9482 | Val Loss: 0.0587 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.54 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.1329 Acc: 0.9565 | Val Loss: 0.0574 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.03 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.1169 Acc: 0.9565 | Val Loss: 0.0772 Acc: 0.9535 | Mem: 2745.52MB | Speed: 216.45 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.1163 Acc: 0.9671 | Val Loss: 0.0617 Acc: 0.9651 | Mem: 2745.52MB | Speed: 216.06 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.0984 Acc: 0.9635 | Val Loss: 0.0801 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.86 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.0936 Acc: 0.9659 | Val Loss: 0.0471 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.46 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0932 Acc: 0.9635 | Val Loss: 0.1072 Acc: 0.9419 | Mem: 2745.52MB | Speed: 216.24 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.1251 Acc: 0.9494 | Val Loss: 0.0396 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.17 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0833 Acc: 0.9706 | Val Loss: 0.0360 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.73 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0943 Acc: 0.9647 | Val Loss: 0.0401 Acc: 0.9767 | Mem: 2745.52MB | Speed: 215.90 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0943 Acc: 0.9612 | Val Loss: 0.0780 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.39 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0961 Acc: 0.9635 | Val Loss: 0.0556 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.26 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0805 Acc: 0.9718 | Val Loss: 0.0584 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.21 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0743 Acc: 0.9776 | Val Loss: 0.0558 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.44 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0999 Acc: 0.9612 | Val Loss: 0.0803 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.46 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0725 Acc: 0.9753 | Val Loss: 0.0931 Acc: 0.9767 | Mem: 2745.52MB | Speed: 215.45 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0835 Acc: 0.9682 | Val Loss: 0.1442 Acc: 0.9651 | Mem: 2745.52MB | Speed: 215.33 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0848 Acc: 0.9682 | Val Loss: 0.0633 Acc: 0.9651 | Mem: 2745.52MB | Speed: 216.82 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0791 Acc: 0.9753 | Val Loss: 0.1130 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.63 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0667 Acc: 0.9788 | Val Loss: 0.0667 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.69 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0866 Acc: 0.9706 | Val Loss: 0.0802 Acc: 0.9651 | Mem: 2745.52MB | Speed: 216.09 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0700 Acc: 0.9812 | Val Loss: 0.0889 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.99 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0471 Acc: 0.9859 | Val Loss: 0.1156 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.12 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0579 Acc: 0.9765 | Val Loss: 0.1301 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.97 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0406 Acc: 0.9859 | Val Loss: 0.1320 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.58 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0648 Acc: 0.9776 | Val Loss: 0.0843 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.40 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0556 Acc: 0.9835 | Val Loss: 0.0504 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.22 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0764 Acc: 0.9753 | Val Loss: 0.0642 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.14 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0423 Acc: 0.9859 | Val Loss: 0.0823 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.11 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0387 Acc: 0.9882 | Val Loss: 0.0626 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.35 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0674 Acc: 0.9753 | Val Loss: 0.1054 Acc: 0.9651 | Mem: 2745.52MB | Speed: 217.58 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0469 Acc: 0.9800 | Val Loss: 0.0866 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.52 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0646 Acc: 0.9718 | Val Loss: 0.1272 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.81 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0478 Acc: 0.9800 | Val Loss: 0.0962 Acc: 0.9767 | Mem: 2745.52MB | Speed: 219.25 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0491 Acc: 0.9788 | Val Loss: 0.0489 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.31 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0437 Acc: 0.9847 | Val Loss: 0.0420 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.64 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0445 Acc: 0.9871 | Val Loss: 0.0201 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.48 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0435 Acc: 0.9824 | Val Loss: 0.0201 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.56 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0508 Acc: 0.9812 | Val Loss: 0.0499 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.40 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0404 Acc: 0.9847 | Val Loss: 0.0316 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.50 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0452 Acc: 0.9835 | Val Loss: 0.0358 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.06 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0509 Acc: 0.9812 | Val Loss: 0.0354 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.51 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0473 Acc: 0.9812 | Val Loss: 0.0658 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.82 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0524 Acc: 0.9800 | Val Loss: 0.0291 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.61 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0417 Acc: 0.9812 | Val Loss: 0.0455 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.71 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0567 Acc: 0.9824 | Val Loss: 0.0643 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.98 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0537 Acc: 0.9812 | Val Loss: 0.0180 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.04 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0439 Acc: 0.9824 | Val Loss: 0.0293 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.64 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0345 Acc: 0.9894 | Val Loss: 0.0459 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.03 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0507 Acc: 0.9812 | Val Loss: 0.0431 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.15 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0387 Acc: 0.9859 | Val Loss: 0.0168 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.03 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0374 Acc: 0.9882 | Val Loss: 0.0114 Acc: 0.9884 | Mem: 2745.52MB | Speed: 219.49 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0457 Acc: 0.9835 | Val Loss: 0.0197 Acc: 0.9884 | Mem: 2745.52MB | Speed: 219.19 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0575 Acc: 0.9835 | Val Loss: 0.0107 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.89 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0570 Acc: 0.9788 | Val Loss: 0.0218 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.87 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0522 Acc: 0.9788 | Val Loss: 0.0109 Acc: 1.0000 | Mem: 2745.52MB | Speed: 218.09 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0334 Acc: 0.9882 | Val Loss: 0.0388 Acc: 0.9884 | Mem: 2745.52MB | Speed: 219.51 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0518 Acc: 0.9835 | Val Loss: 0.0625 Acc: 0.9884 | Mem: 2745.52MB | Speed: 219.17 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0508 Acc: 0.9835 | Val Loss: 0.0164 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.72 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0464 Acc: 0.9835 | Val Loss: 0.0451 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.89 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0522 Acc: 0.9824 | Val Loss: 0.0020 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.35 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0653 Acc: 0.9753 | Val Loss: 0.0254 Acc: 0.9884 | Mem: 2745.52MB | Speed: 218.28 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0469 Acc: 0.9788 | Val Loss: 0.0515 Acc: 0.9767 | Mem: 2745.52MB | Speed: 217.95 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0467 Acc: 0.9859 | Val Loss: 0.0180 Acc: 0.9884 | Mem: 2745.52MB | Speed: 219.98 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0501 Acc: 0.9847 | Val Loss: 0.0097 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.10 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0334 Acc: 0.9859 | Val Loss: 0.0189 Acc: 0.9884 | Mem: 2745.52MB | Speed: 219.62 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0436 Acc: 0.9835 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.59 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0624 Acc: 0.9800 | Val Loss: 0.0038 Acc: 1.0000 | Mem: 2745.52MB | Speed: 220.03 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0511 Acc: 0.9812 | Val Loss: 0.0008 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.25 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0411 Acc: 0.9882 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.17 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0620 Acc: 0.9800 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.55 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0333 Acc: 0.9871 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2745.52MB | Speed: 218.47 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0295 Acc: 0.9894 | Val Loss: 0.0053 Acc: 1.0000 | Mem: 2745.52MB | Speed: 218.47 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0265 Acc: 0.9906 | Val Loss: 0.0149 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.74 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0411 Acc: 0.9859 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 219.10 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0242 Acc: 0.9894 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2745.52MB | Speed: 218.07 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0356 Acc: 0.9859 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.52 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0338 Acc: 0.9847 | Val Loss: 0.0039 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.20 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0318 Acc: 0.9882 | Val Loss: 0.0010 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.50 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0338 Acc: 0.9882 | Val Loss: 0.1069 Acc: 0.9767 | Mem: 2745.52MB | Speed: 216.95 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0424 Acc: 0.9871 | Val Loss: 0.0249 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.85 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0432 Acc: 0.9859 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.32 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0341 Acc: 0.9882 | Val Loss: 0.0810 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.65 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0487 Acc: 0.9859 | Val Loss: 0.0048 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.02 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0227 Acc: 0.9918 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.52 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0267 Acc: 0.9859 | Val Loss: 0.0228 Acc: 0.9884 | Mem: 2745.52MB | Speed: 217.43 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0420 Acc: 0.9835 | Val Loss: 0.0011 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.46 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0451 Acc: 0.9871 | Val Loss: 0.0060 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.85 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0336 Acc: 0.9906 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.14 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0324 Acc: 0.9929 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.37 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0214 Acc: 0.9929 | Val Loss: 0.0018 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.40 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0231 Acc: 0.9929 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2745.52MB | Speed: 215.53 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0395 Acc: 0.9859 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2745.52MB | Speed: 215.22 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0336 Acc: 0.9882 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.69 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0292 Acc: 0.9918 | Val Loss: 0.0021 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.14 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0387 Acc: 0.9859 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 218.02 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0267 Acc: 0.9906 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 218.17 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0229 Acc: 0.9906 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.63 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0340 Acc: 0.9882 | Val Loss: 0.0014 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.51 samples/s\n",
      "Epoch 124/1000 | Train Loss: 0.0451 Acc: 0.9859 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.14 samples/s\n",
      "Epoch 125/1000 | Train Loss: 0.0402 Acc: 0.9859 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.19 samples/s\n",
      "Epoch 126/1000 | Train Loss: 0.0308 Acc: 0.9906 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 217.17 samples/s\n",
      "Epoch 127/1000 | Train Loss: 0.0197 Acc: 0.9929 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.37 samples/s\n",
      "Epoch 128/1000 | Train Loss: 0.0252 Acc: 0.9859 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.73 samples/s\n",
      "Epoch 129/1000 | Train Loss: 0.0256 Acc: 0.9894 | Val Loss: 0.0008 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.62 samples/s\n",
      "Epoch 130/1000 | Train Loss: 0.0193 Acc: 0.9918 | Val Loss: 0.0052 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.19 samples/s\n",
      "Epoch 131/1000 | Train Loss: 0.0358 Acc: 0.9882 | Val Loss: 0.0176 Acc: 0.9884 | Mem: 2745.52MB | Speed: 216.22 samples/s\n",
      "Epoch 132/1000 | Train Loss: 0.0279 Acc: 0.9906 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.32 samples/s\n",
      "Epoch 133/1000 | Train Loss: 0.0391 Acc: 0.9859 | Val Loss: 0.0025 Acc: 1.0000 | Mem: 2745.52MB | Speed: 216.49 samples/s\n",
      "Stopping early at epoch 133 (no improvement in 100 epochs).\n",
      "Subject 4 final accuracy: 0.7153\n",
      "seed is 1258\n",
      "Subject 5\n",
      "Epoch 1/1000 | Train Loss: 1.2153 Acc: 0.4659 | Val Loss: 0.9384 Acc: 0.5930 | Mem: 2753.90MB | Speed: 218.03 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.8107 Acc: 0.7082 | Val Loss: 0.7964 Acc: 0.6512 | Mem: 2754.66MB | Speed: 216.85 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.5963 Acc: 0.7671 | Val Loss: 0.6034 Acc: 0.7442 | Mem: 2754.66MB | Speed: 217.29 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.5234 Acc: 0.8106 | Val Loss: 0.4840 Acc: 0.8372 | Mem: 2754.66MB | Speed: 216.66 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.4379 Acc: 0.8388 | Val Loss: 0.4045 Acc: 0.8605 | Mem: 2754.66MB | Speed: 216.05 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.3608 Acc: 0.8718 | Val Loss: 0.3273 Acc: 0.8953 | Mem: 2754.66MB | Speed: 215.81 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.2982 Acc: 0.8941 | Val Loss: 0.2350 Acc: 0.9186 | Mem: 2754.66MB | Speed: 216.56 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.3060 Acc: 0.8918 | Val Loss: 0.1702 Acc: 0.9419 | Mem: 2754.66MB | Speed: 216.52 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.2736 Acc: 0.9035 | Val Loss: 0.1809 Acc: 0.9302 | Mem: 2754.66MB | Speed: 215.84 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.2334 Acc: 0.9224 | Val Loss: 0.1346 Acc: 0.9419 | Mem: 2754.66MB | Speed: 216.88 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.2217 Acc: 0.9176 | Val Loss: 0.1141 Acc: 0.9651 | Mem: 2754.66MB | Speed: 215.32 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.1728 Acc: 0.9365 | Val Loss: 0.1082 Acc: 0.9767 | Mem: 2754.66MB | Speed: 215.44 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.1597 Acc: 0.9506 | Val Loss: 0.1731 Acc: 0.9535 | Mem: 2754.66MB | Speed: 215.31 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.1548 Acc: 0.9518 | Val Loss: 0.1142 Acc: 0.9651 | Mem: 2754.66MB | Speed: 215.86 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.1492 Acc: 0.9541 | Val Loss: 0.1302 Acc: 0.9651 | Mem: 2754.66MB | Speed: 216.30 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.1541 Acc: 0.9494 | Val Loss: 0.1323 Acc: 0.9651 | Mem: 2754.66MB | Speed: 215.71 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.1158 Acc: 0.9624 | Val Loss: 0.1180 Acc: 0.9535 | Mem: 2754.66MB | Speed: 216.67 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.1212 Acc: 0.9529 | Val Loss: 0.0748 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.79 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.1077 Acc: 0.9647 | Val Loss: 0.0616 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.22 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.1138 Acc: 0.9588 | Val Loss: 0.0629 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.73 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.0947 Acc: 0.9706 | Val Loss: 0.0659 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.08 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.0909 Acc: 0.9718 | Val Loss: 0.0598 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.75 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.0940 Acc: 0.9753 | Val Loss: 0.0472 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.27 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.0871 Acc: 0.9729 | Val Loss: 0.0298 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.60 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.0798 Acc: 0.9741 | Val Loss: 0.0196 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.01 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.0883 Acc: 0.9647 | Val Loss: 0.0286 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.60 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.0738 Acc: 0.9729 | Val Loss: 0.0134 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.98 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.0725 Acc: 0.9788 | Val Loss: 0.0411 Acc: 0.9884 | Mem: 2754.66MB | Speed: 215.24 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.0642 Acc: 0.9835 | Val Loss: 0.0425 Acc: 0.9884 | Mem: 2754.66MB | Speed: 215.96 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.0585 Acc: 0.9871 | Val Loss: 0.0136 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.35 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0589 Acc: 0.9835 | Val Loss: 0.0088 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.80 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.0549 Acc: 0.9824 | Val Loss: 0.0098 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.06 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0690 Acc: 0.9788 | Val Loss: 0.0229 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.02 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0536 Acc: 0.9835 | Val Loss: 0.0312 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.48 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0681 Acc: 0.9753 | Val Loss: 0.0105 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.24 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0683 Acc: 0.9800 | Val Loss: 0.0117 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.49 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0649 Acc: 0.9741 | Val Loss: 0.0100 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.33 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0477 Acc: 0.9835 | Val Loss: 0.0147 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.37 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0557 Acc: 0.9812 | Val Loss: 0.0208 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.44 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0591 Acc: 0.9812 | Val Loss: 0.0711 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.42 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0680 Acc: 0.9706 | Val Loss: 0.0475 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.70 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0588 Acc: 0.9812 | Val Loss: 0.0078 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.28 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0490 Acc: 0.9776 | Val Loss: 0.0273 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.21 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0517 Acc: 0.9776 | Val Loss: 0.0169 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.88 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0444 Acc: 0.9812 | Val Loss: 0.0072 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.22 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0395 Acc: 0.9906 | Val Loss: 0.0300 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.18 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0468 Acc: 0.9859 | Val Loss: 0.0398 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.69 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0430 Acc: 0.9859 | Val Loss: 0.0571 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.43 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0605 Acc: 0.9765 | Val Loss: 0.0334 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.51 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0338 Acc: 0.9882 | Val Loss: 0.0207 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.22 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0361 Acc: 0.9918 | Val Loss: 0.0246 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.36 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0288 Acc: 0.9906 | Val Loss: 0.0253 Acc: 0.9884 | Mem: 2754.66MB | Speed: 215.89 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0440 Acc: 0.9835 | Val Loss: 0.0194 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.05 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0374 Acc: 0.9882 | Val Loss: 0.0068 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.29 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0350 Acc: 0.9871 | Val Loss: 0.0054 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.75 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0317 Acc: 0.9882 | Val Loss: 0.0419 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.25 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0488 Acc: 0.9859 | Val Loss: 0.0126 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.04 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0364 Acc: 0.9871 | Val Loss: 0.0531 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.16 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0272 Acc: 0.9918 | Val Loss: 0.0753 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.78 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0391 Acc: 0.9882 | Val Loss: 0.0210 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.16 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0413 Acc: 0.9882 | Val Loss: 0.0237 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.14 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0345 Acc: 0.9882 | Val Loss: 0.0493 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.25 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0395 Acc: 0.9859 | Val Loss: 0.0590 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.21 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0448 Acc: 0.9812 | Val Loss: 0.0372 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.53 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0290 Acc: 0.9894 | Val Loss: 0.0077 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.54 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0439 Acc: 0.9835 | Val Loss: 0.0079 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.10 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0312 Acc: 0.9929 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.53 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0300 Acc: 0.9894 | Val Loss: 0.0008 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.15 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0223 Acc: 0.9918 | Val Loss: 0.0021 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.57 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0423 Acc: 0.9894 | Val Loss: 0.0022 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.95 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0257 Acc: 0.9929 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.13 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0403 Acc: 0.9871 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.02 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0392 Acc: 0.9882 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.62 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0268 Acc: 0.9906 | Val Loss: 0.0038 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.08 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0239 Acc: 0.9906 | Val Loss: 0.0050 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.64 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0168 Acc: 0.9965 | Val Loss: 0.0012 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.90 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0470 Acc: 0.9882 | Val Loss: 0.0074 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.82 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0291 Acc: 0.9894 | Val Loss: 0.0029 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.59 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0307 Acc: 0.9906 | Val Loss: 0.0127 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.02 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0201 Acc: 0.9918 | Val Loss: 0.0014 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.02 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0315 Acc: 0.9871 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.61 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0277 Acc: 0.9906 | Val Loss: 0.0221 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.25 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0428 Acc: 0.9824 | Val Loss: 0.0010 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.45 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0332 Acc: 0.9835 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.70 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0229 Acc: 0.9894 | Val Loss: 0.0014 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.91 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0271 Acc: 0.9918 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.58 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0225 Acc: 0.9941 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.65 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0344 Acc: 0.9859 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.61 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0291 Acc: 0.9871 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.60 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0283 Acc: 0.9882 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.05 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0489 Acc: 0.9859 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.11 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0240 Acc: 0.9906 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.38 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0471 Acc: 0.9800 | Val Loss: 0.0066 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.72 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0334 Acc: 0.9835 | Val Loss: 0.0091 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.48 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0327 Acc: 0.9871 | Val Loss: 0.0099 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.62 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0303 Acc: 0.9859 | Val Loss: 0.0042 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.26 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0262 Acc: 0.9882 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.37 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0233 Acc: 0.9929 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.60 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0411 Acc: 0.9894 | Val Loss: 0.0075 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.29 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0231 Acc: 0.9918 | Val Loss: 0.0112 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.40 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0282 Acc: 0.9906 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.16 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0410 Acc: 0.9859 | Val Loss: 0.0010 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.16 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0350 Acc: 0.9882 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.54 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0326 Acc: 0.9882 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.99 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0414 Acc: 0.9882 | Val Loss: 0.0011 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.27 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0415 Acc: 0.9882 | Val Loss: 0.0547 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.45 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0298 Acc: 0.9906 | Val Loss: 0.0132 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.55 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0221 Acc: 0.9941 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.57 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0245 Acc: 0.9894 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.12 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0260 Acc: 0.9871 | Val Loss: 0.0088 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.74 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0175 Acc: 0.9929 | Val Loss: 0.0159 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.39 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0186 Acc: 0.9953 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.07 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0065 Acc: 0.9988 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.96 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0429 Acc: 0.9835 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.17 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0187 Acc: 0.9929 | Val Loss: 0.0022 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.88 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0156 Acc: 0.9929 | Val Loss: 0.0020 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.96 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0195 Acc: 0.9953 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.19 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0178 Acc: 0.9929 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.64 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0273 Acc: 0.9871 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.63 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0294 Acc: 0.9929 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.91 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0282 Acc: 0.9894 | Val Loss: 0.0035 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.35 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0250 Acc: 0.9894 | Val Loss: 0.0067 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.60 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0288 Acc: 0.9871 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.66 samples/s\n",
      "Epoch 124/1000 | Train Loss: 0.0169 Acc: 0.9929 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.66 samples/s\n",
      "Epoch 125/1000 | Train Loss: 0.0162 Acc: 0.9953 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.81 samples/s\n",
      "Epoch 126/1000 | Train Loss: 0.0343 Acc: 0.9941 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.26 samples/s\n",
      "Epoch 127/1000 | Train Loss: 0.0141 Acc: 0.9965 | Val Loss: 0.0011 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.93 samples/s\n",
      "Epoch 128/1000 | Train Loss: 0.0388 Acc: 0.9847 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.70 samples/s\n",
      "Epoch 129/1000 | Train Loss: 0.0130 Acc: 0.9965 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.78 samples/s\n",
      "Epoch 130/1000 | Train Loss: 0.0188 Acc: 0.9941 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.86 samples/s\n",
      "Epoch 131/1000 | Train Loss: 0.0269 Acc: 0.9918 | Val Loss: 0.0048 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.95 samples/s\n",
      "Epoch 132/1000 | Train Loss: 0.0184 Acc: 0.9929 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.83 samples/s\n",
      "Epoch 133/1000 | Train Loss: 0.0149 Acc: 0.9953 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.90 samples/s\n",
      "Epoch 134/1000 | Train Loss: 0.0236 Acc: 0.9929 | Val Loss: 0.0015 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.70 samples/s\n",
      "Epoch 135/1000 | Train Loss: 0.0432 Acc: 0.9847 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.08 samples/s\n",
      "Stopping early at epoch 135 (no improvement in 100 epochs).\n",
      "Subject 5 final accuracy: 0.7188\n",
      "seed is 1880\n",
      "Subject 6\n",
      "Epoch 1/1000 | Train Loss: 1.3156 Acc: 0.3882 | Val Loss: 1.1168 Acc: 0.5581 | Mem: 2754.66MB | Speed: 217.91 samples/s\n",
      "Epoch 2/1000 | Train Loss: 1.0370 Acc: 0.5671 | Val Loss: 1.2196 Acc: 0.5349 | Mem: 2754.30MB | Speed: 216.62 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.9303 Acc: 0.6259 | Val Loss: 0.9260 Acc: 0.6860 | Mem: 2754.30MB | Speed: 217.94 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.7643 Acc: 0.6953 | Val Loss: 0.8886 Acc: 0.6395 | Mem: 2754.30MB | Speed: 217.66 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.6552 Acc: 0.7553 | Val Loss: 0.6984 Acc: 0.7093 | Mem: 2754.30MB | Speed: 217.50 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.5345 Acc: 0.7965 | Val Loss: 0.5855 Acc: 0.8023 | Mem: 2754.30MB | Speed: 217.40 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.4772 Acc: 0.8047 | Val Loss: 0.4746 Acc: 0.8140 | Mem: 2754.30MB | Speed: 216.76 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.3956 Acc: 0.8482 | Val Loss: 0.4281 Acc: 0.8256 | Mem: 2754.30MB | Speed: 217.44 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.3758 Acc: 0.8541 | Val Loss: 0.3742 Acc: 0.8721 | Mem: 2754.30MB | Speed: 215.28 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.3238 Acc: 0.8835 | Val Loss: 0.4480 Acc: 0.8605 | Mem: 2754.30MB | Speed: 215.95 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.2756 Acc: 0.9000 | Val Loss: 0.3480 Acc: 0.8605 | Mem: 2754.30MB | Speed: 217.05 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.2759 Acc: 0.9059 | Val Loss: 0.3291 Acc: 0.8605 | Mem: 2754.30MB | Speed: 217.17 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.2138 Acc: 0.9294 | Val Loss: 0.2773 Acc: 0.8721 | Mem: 2754.30MB | Speed: 216.05 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.2017 Acc: 0.9306 | Val Loss: 0.2632 Acc: 0.9070 | Mem: 2754.30MB | Speed: 215.49 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.1953 Acc: 0.9259 | Val Loss: 0.1891 Acc: 0.9186 | Mem: 2754.30MB | Speed: 216.92 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.1688 Acc: 0.9282 | Val Loss: 0.1454 Acc: 0.9419 | Mem: 2754.30MB | Speed: 216.83 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.2015 Acc: 0.9118 | Val Loss: 0.1353 Acc: 0.9302 | Mem: 2754.30MB | Speed: 216.86 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.1738 Acc: 0.9435 | Val Loss: 0.0970 Acc: 0.9302 | Mem: 2754.30MB | Speed: 217.30 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.1954 Acc: 0.9376 | Val Loss: 0.0847 Acc: 0.9651 | Mem: 2754.30MB | Speed: 218.23 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.1532 Acc: 0.9388 | Val Loss: 0.0890 Acc: 0.9651 | Mem: 2754.30MB | Speed: 217.09 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.1351 Acc: 0.9553 | Val Loss: 0.0816 Acc: 0.9651 | Mem: 2754.30MB | Speed: 217.69 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.1373 Acc: 0.9529 | Val Loss: 0.0995 Acc: 0.9535 | Mem: 2754.30MB | Speed: 216.23 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.1493 Acc: 0.9482 | Val Loss: 0.0798 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.14 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.1476 Acc: 0.9459 | Val Loss: 0.0752 Acc: 0.9651 | Mem: 2754.30MB | Speed: 217.10 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.1193 Acc: 0.9565 | Val Loss: 0.0876 Acc: 0.9535 | Mem: 2754.30MB | Speed: 216.61 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.1144 Acc: 0.9576 | Val Loss: 0.0782 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.45 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.1088 Acc: 0.9647 | Val Loss: 0.1115 Acc: 0.9535 | Mem: 2754.30MB | Speed: 217.89 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.1174 Acc: 0.9588 | Val Loss: 0.0694 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.86 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.1368 Acc: 0.9447 | Val Loss: 0.0818 Acc: 0.9767 | Mem: 2754.30MB | Speed: 215.49 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.1268 Acc: 0.9412 | Val Loss: 0.0426 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.34 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.1003 Acc: 0.9612 | Val Loss: 0.0285 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.47 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.1057 Acc: 0.9635 | Val Loss: 0.0245 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.65 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.1099 Acc: 0.9647 | Val Loss: 0.0415 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.77 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.1079 Acc: 0.9576 | Val Loss: 0.0407 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.75 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0894 Acc: 0.9659 | Val Loss: 0.0189 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.09 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0968 Acc: 0.9612 | Val Loss: 0.0203 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.10 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0922 Acc: 0.9694 | Val Loss: 0.0512 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.63 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0833 Acc: 0.9718 | Val Loss: 0.0232 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.77 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0920 Acc: 0.9729 | Val Loss: 0.0205 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.83 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0833 Acc: 0.9647 | Val Loss: 0.0678 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.66 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0775 Acc: 0.9765 | Val Loss: 0.0592 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.90 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0675 Acc: 0.9741 | Val Loss: 0.0304 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.85 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0702 Acc: 0.9765 | Val Loss: 0.0316 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.07 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0501 Acc: 0.9835 | Val Loss: 0.0532 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.02 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0671 Acc: 0.9753 | Val Loss: 0.0824 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.78 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0628 Acc: 0.9788 | Val Loss: 0.0773 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.59 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0801 Acc: 0.9682 | Val Loss: 0.1203 Acc: 0.9651 | Mem: 2754.30MB | Speed: 216.86 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0811 Acc: 0.9729 | Val Loss: 0.0807 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.99 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0626 Acc: 0.9824 | Val Loss: 0.0567 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.05 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0614 Acc: 0.9765 | Val Loss: 0.0535 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.54 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0661 Acc: 0.9765 | Val Loss: 0.0234 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.43 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0525 Acc: 0.9800 | Val Loss: 0.0109 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.65 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0653 Acc: 0.9800 | Val Loss: 0.0363 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.09 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0651 Acc: 0.9753 | Val Loss: 0.0053 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.45 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0561 Acc: 0.9776 | Val Loss: 0.0036 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.35 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0416 Acc: 0.9871 | Val Loss: 0.0032 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.16 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0554 Acc: 0.9776 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2754.30MB | Speed: 218.17 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0580 Acc: 0.9800 | Val Loss: 0.0037 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.81 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0807 Acc: 0.9729 | Val Loss: 0.0044 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.20 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0698 Acc: 0.9824 | Val Loss: 0.0071 Acc: 1.0000 | Mem: 2754.30MB | Speed: 215.98 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0489 Acc: 0.9824 | Val Loss: 0.0139 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.98 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0540 Acc: 0.9835 | Val Loss: 0.0094 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.97 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0481 Acc: 0.9847 | Val Loss: 0.0078 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.29 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0641 Acc: 0.9765 | Val Loss: 0.0563 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.99 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0502 Acc: 0.9812 | Val Loss: 0.0051 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.39 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0399 Acc: 0.9859 | Val Loss: 0.0119 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.11 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0643 Acc: 0.9812 | Val Loss: 0.0091 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.32 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0614 Acc: 0.9753 | Val Loss: 0.0080 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.85 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0640 Acc: 0.9824 | Val Loss: 0.0296 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.77 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0551 Acc: 0.9824 | Val Loss: 0.0028 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.34 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0452 Acc: 0.9847 | Val Loss: 0.0091 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.99 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0362 Acc: 0.9882 | Val Loss: 0.0055 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.80 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0377 Acc: 0.9871 | Val Loss: 0.0008 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.27 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0383 Acc: 0.9859 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.05 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0585 Acc: 0.9835 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.29 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0464 Acc: 0.9835 | Val Loss: 0.0097 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.91 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0419 Acc: 0.9847 | Val Loss: 0.0208 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.03 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0374 Acc: 0.9847 | Val Loss: 0.0036 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.58 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0546 Acc: 0.9753 | Val Loss: 0.0053 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.60 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0439 Acc: 0.9859 | Val Loss: 0.0014 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.51 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0343 Acc: 0.9882 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.17 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0271 Acc: 0.9906 | Val Loss: 0.0020 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.79 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0334 Acc: 0.9871 | Val Loss: 0.0060 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.59 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0339 Acc: 0.9859 | Val Loss: 0.0091 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.53 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0452 Acc: 0.9859 | Val Loss: 0.0479 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.99 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0376 Acc: 0.9894 | Val Loss: 0.1182 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.65 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0439 Acc: 0.9882 | Val Loss: 0.0070 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.78 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0396 Acc: 0.9847 | Val Loss: 0.0228 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.78 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0267 Acc: 0.9871 | Val Loss: 0.0734 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.59 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0482 Acc: 0.9847 | Val Loss: 0.0137 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.53 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0319 Acc: 0.9871 | Val Loss: 0.0467 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.63 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0305 Acc: 0.9871 | Val Loss: 0.0349 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.03 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0591 Acc: 0.9776 | Val Loss: 0.0056 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.71 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0525 Acc: 0.9812 | Val Loss: 0.0020 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.97 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0384 Acc: 0.9859 | Val Loss: 0.0041 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.02 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0281 Acc: 0.9835 | Val Loss: 0.0100 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.23 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0466 Acc: 0.9824 | Val Loss: 0.0012 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.18 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0457 Acc: 0.9835 | Val Loss: 0.0011 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.05 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0398 Acc: 0.9847 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2754.30MB | Speed: 215.96 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0525 Acc: 0.9812 | Val Loss: 0.0010 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.63 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0413 Acc: 0.9859 | Val Loss: 0.0012 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.18 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0298 Acc: 0.9906 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.54 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0323 Acc: 0.9882 | Val Loss: 0.0034 Acc: 1.0000 | Mem: 2754.30MB | Speed: 215.75 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0378 Acc: 0.9859 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.97 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0273 Acc: 0.9906 | Val Loss: 0.0040 Acc: 1.0000 | Mem: 2754.30MB | Speed: 215.73 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0406 Acc: 0.9859 | Val Loss: 0.0044 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.81 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0300 Acc: 0.9847 | Val Loss: 0.0023 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.24 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0341 Acc: 0.9894 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.31 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0263 Acc: 0.9918 | Val Loss: 0.0018 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.69 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0445 Acc: 0.9847 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.71 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0354 Acc: 0.9871 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.75 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0284 Acc: 0.9894 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.03 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0378 Acc: 0.9859 | Val Loss: 0.0026 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.92 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0394 Acc: 0.9882 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.19 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0345 Acc: 0.9871 | Val Loss: 0.0014 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.76 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0354 Acc: 0.9894 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.00 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0349 Acc: 0.9882 | Val Loss: 0.0015 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.65 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0337 Acc: 0.9882 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.52 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0328 Acc: 0.9894 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.80 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0384 Acc: 0.9859 | Val Loss: 0.0083 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.12 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0226 Acc: 0.9918 | Val Loss: 0.0046 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.28 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0159 Acc: 0.9965 | Val Loss: 0.0247 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.52 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0496 Acc: 0.9859 | Val Loss: 0.0172 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.06 samples/s\n",
      "Epoch 124/1000 | Train Loss: 0.0635 Acc: 0.9800 | Val Loss: 0.0065 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.95 samples/s\n",
      "Epoch 125/1000 | Train Loss: 0.0375 Acc: 0.9871 | Val Loss: 0.0179 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.11 samples/s\n",
      "Epoch 126/1000 | Train Loss: 0.0394 Acc: 0.9847 | Val Loss: 0.0403 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.41 samples/s\n",
      "Epoch 127/1000 | Train Loss: 0.0430 Acc: 0.9871 | Val Loss: 0.0247 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.86 samples/s\n",
      "Epoch 128/1000 | Train Loss: 0.0434 Acc: 0.9847 | Val Loss: 0.0349 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.56 samples/s\n",
      "Epoch 129/1000 | Train Loss: 0.0204 Acc: 0.9953 | Val Loss: 0.0315 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.18 samples/s\n",
      "Epoch 130/1000 | Train Loss: 0.0415 Acc: 0.9871 | Val Loss: 0.0028 Acc: 1.0000 | Mem: 2754.30MB | Speed: 217.34 samples/s\n",
      "Epoch 131/1000 | Train Loss: 0.0423 Acc: 0.9835 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.79 samples/s\n",
      "Epoch 132/1000 | Train Loss: 0.0282 Acc: 0.9918 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.99 samples/s\n",
      "Epoch 133/1000 | Train Loss: 0.0488 Acc: 0.9824 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.64 samples/s\n",
      "Epoch 134/1000 | Train Loss: 0.0195 Acc: 0.9965 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.05 samples/s\n",
      "Epoch 135/1000 | Train Loss: 0.0263 Acc: 0.9894 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.46 samples/s\n",
      "Epoch 136/1000 | Train Loss: 0.0520 Acc: 0.9788 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.71 samples/s\n",
      "Stopping early at epoch 136 (no improvement in 100 epochs).\n",
      "Subject 6 final accuracy: 0.6007\n",
      "seed is 76\n",
      "Subject 7\n",
      "Epoch 1/1000 | Train Loss: 1.1694 Acc: 0.4882 | Val Loss: 0.9357 Acc: 0.5814 | Mem: 2753.90MB | Speed: 216.89 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.8089 Acc: 0.6647 | Val Loss: 0.7640 Acc: 0.6512 | Mem: 2754.66MB | Speed: 217.14 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.5896 Acc: 0.7600 | Val Loss: 0.6217 Acc: 0.7326 | Mem: 2754.66MB | Speed: 216.56 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.4390 Acc: 0.8471 | Val Loss: 0.4991 Acc: 0.8023 | Mem: 2754.66MB | Speed: 217.21 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.4042 Acc: 0.8518 | Val Loss: 0.3445 Acc: 0.8605 | Mem: 2754.66MB | Speed: 215.62 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.3441 Acc: 0.8765 | Val Loss: 0.2387 Acc: 0.9419 | Mem: 2754.66MB | Speed: 216.21 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.2832 Acc: 0.8988 | Val Loss: 0.1958 Acc: 0.8837 | Mem: 2754.66MB | Speed: 216.83 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.2045 Acc: 0.9353 | Val Loss: 0.1881 Acc: 0.9302 | Mem: 2754.66MB | Speed: 217.69 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.2069 Acc: 0.9212 | Val Loss: 0.1800 Acc: 0.9186 | Mem: 2754.66MB | Speed: 216.31 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.2226 Acc: 0.9082 | Val Loss: 0.1673 Acc: 0.9186 | Mem: 2754.66MB | Speed: 217.84 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.2134 Acc: 0.9259 | Val Loss: 0.1348 Acc: 0.9535 | Mem: 2754.66MB | Speed: 216.91 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.1801 Acc: 0.9329 | Val Loss: 0.1151 Acc: 0.9419 | Mem: 2754.66MB | Speed: 216.62 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.1624 Acc: 0.9412 | Val Loss: 0.1241 Acc: 0.9186 | Mem: 2754.66MB | Speed: 215.51 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.1568 Acc: 0.9435 | Val Loss: 0.1210 Acc: 0.9535 | Mem: 2754.66MB | Speed: 216.01 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.1556 Acc: 0.9400 | Val Loss: 0.1101 Acc: 0.9535 | Mem: 2754.66MB | Speed: 216.72 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.1188 Acc: 0.9565 | Val Loss: 0.1086 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.46 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.1330 Acc: 0.9494 | Val Loss: 0.0873 Acc: 0.9535 | Mem: 2754.66MB | Speed: 216.72 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.1179 Acc: 0.9635 | Val Loss: 0.0831 Acc: 0.9651 | Mem: 2754.66MB | Speed: 217.84 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.0906 Acc: 0.9706 | Val Loss: 0.0759 Acc: 0.9419 | Mem: 2754.66MB | Speed: 217.38 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.1074 Acc: 0.9682 | Val Loss: 0.0788 Acc: 0.9651 | Mem: 2754.66MB | Speed: 216.57 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.0926 Acc: 0.9729 | Val Loss: 0.0927 Acc: 0.9651 | Mem: 2754.66MB | Speed: 217.54 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.0922 Acc: 0.9694 | Val Loss: 0.0592 Acc: 0.9651 | Mem: 2754.66MB | Speed: 217.17 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.0734 Acc: 0.9776 | Val Loss: 0.0652 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.44 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.0784 Acc: 0.9788 | Val Loss: 0.0545 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.24 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.0803 Acc: 0.9729 | Val Loss: 0.0633 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.43 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.0923 Acc: 0.9694 | Val Loss: 0.0624 Acc: 0.9535 | Mem: 2754.66MB | Speed: 216.23 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.0649 Acc: 0.9776 | Val Loss: 0.0601 Acc: 0.9651 | Mem: 2754.66MB | Speed: 215.04 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.0737 Acc: 0.9776 | Val Loss: 0.0548 Acc: 0.9767 | Mem: 2754.66MB | Speed: 215.63 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.1065 Acc: 0.9635 | Val Loss: 0.0627 Acc: 0.9419 | Mem: 2754.66MB | Speed: 216.42 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.1047 Acc: 0.9600 | Val Loss: 0.2015 Acc: 0.9651 | Mem: 2754.66MB | Speed: 217.32 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0905 Acc: 0.9659 | Val Loss: 0.0943 Acc: 0.9651 | Mem: 2754.66MB | Speed: 218.00 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.0723 Acc: 0.9788 | Val Loss: 0.1016 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.18 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0683 Acc: 0.9776 | Val Loss: 0.0789 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.76 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0607 Acc: 0.9824 | Val Loss: 0.0600 Acc: 0.9651 | Mem: 2754.66MB | Speed: 217.16 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0545 Acc: 0.9812 | Val Loss: 0.0480 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.98 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0842 Acc: 0.9682 | Val Loss: 0.0763 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.02 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0651 Acc: 0.9753 | Val Loss: 0.0089 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.93 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0553 Acc: 0.9824 | Val Loss: 0.0075 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.12 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0448 Acc: 0.9859 | Val Loss: 0.0340 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.29 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0525 Acc: 0.9812 | Val Loss: 0.0217 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.56 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0569 Acc: 0.9859 | Val Loss: 0.0345 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.36 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0587 Acc: 0.9741 | Val Loss: 0.0432 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.84 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0447 Acc: 0.9882 | Val Loss: 0.0239 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.63 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0462 Acc: 0.9824 | Val Loss: 0.0191 Acc: 0.9884 | Mem: 2754.66MB | Speed: 218.05 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0400 Acc: 0.9847 | Val Loss: 0.0346 Acc: 0.9767 | Mem: 2754.66MB | Speed: 218.19 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0448 Acc: 0.9859 | Val Loss: 0.0210 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.95 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0425 Acc: 0.9859 | Val Loss: 0.0585 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.81 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0413 Acc: 0.9835 | Val Loss: 0.0329 Acc: 0.9767 | Mem: 2754.66MB | Speed: 217.25 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0324 Acc: 0.9894 | Val Loss: 0.0400 Acc: 0.9767 | Mem: 2754.66MB | Speed: 218.10 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0302 Acc: 0.9929 | Val Loss: 0.0408 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.28 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0313 Acc: 0.9871 | Val Loss: 0.0541 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.82 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0253 Acc: 0.9918 | Val Loss: 0.0276 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.39 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0364 Acc: 0.9906 | Val Loss: 0.0127 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.75 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0342 Acc: 0.9859 | Val Loss: 0.0211 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.35 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0257 Acc: 0.9882 | Val Loss: 0.0072 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.99 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0294 Acc: 0.9906 | Val Loss: 0.0018 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.73 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0335 Acc: 0.9906 | Val Loss: 0.0062 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.29 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0236 Acc: 0.9929 | Val Loss: 0.0165 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.11 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0505 Acc: 0.9835 | Val Loss: 0.0030 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.63 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0223 Acc: 0.9918 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.51 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0170 Acc: 0.9941 | Val Loss: 0.0035 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.91 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0204 Acc: 0.9918 | Val Loss: 0.0010 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.92 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0201 Acc: 0.9918 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.95 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0213 Acc: 0.9929 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.54 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0174 Acc: 0.9965 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.47 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0308 Acc: 0.9941 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.97 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0200 Acc: 0.9941 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.71 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0236 Acc: 0.9906 | Val Loss: 0.0189 Acc: 0.9884 | Mem: 2754.66MB | Speed: 218.81 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0267 Acc: 0.9882 | Val Loss: 0.0267 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.48 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0224 Acc: 0.9918 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.90 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0269 Acc: 0.9906 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.95 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0205 Acc: 0.9953 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.58 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0127 Acc: 0.9965 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.51 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0140 Acc: 0.9953 | Val Loss: 0.0015 Acc: 1.0000 | Mem: 2754.66MB | Speed: 215.83 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0106 Acc: 0.9953 | Val Loss: 0.0024 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.17 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0121 Acc: 0.9953 | Val Loss: 0.0033 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.45 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0301 Acc: 0.9882 | Val Loss: 0.0012 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.93 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0143 Acc: 0.9953 | Val Loss: 0.0034 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.87 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0283 Acc: 0.9918 | Val Loss: 0.0095 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.62 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0181 Acc: 0.9929 | Val Loss: 0.0024 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.61 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0209 Acc: 0.9929 | Val Loss: 0.0008 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.86 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0111 Acc: 0.9976 | Val Loss: 0.0074 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.65 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0209 Acc: 0.9941 | Val Loss: 0.0270 Acc: 0.9767 | Mem: 2754.66MB | Speed: 216.76 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0121 Acc: 0.9953 | Val Loss: 0.0205 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.20 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0238 Acc: 0.9941 | Val Loss: 0.0137 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.50 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0100 Acc: 0.9953 | Val Loss: 0.0042 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.48 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0099 Acc: 0.9988 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.12 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0116 Acc: 0.9953 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.07 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0148 Acc: 0.9918 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.97 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0136 Acc: 0.9941 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.07 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0300 Acc: 0.9906 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.37 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0218 Acc: 0.9906 | Val Loss: 0.0024 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.98 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0094 Acc: 0.9965 | Val Loss: 0.0209 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.71 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0364 Acc: 0.9871 | Val Loss: 0.0333 Acc: 0.9884 | Mem: 2754.66MB | Speed: 216.96 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0307 Acc: 0.9918 | Val Loss: 0.0037 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.25 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0089 Acc: 0.9941 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.83 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0119 Acc: 0.9953 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.68 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0186 Acc: 0.9918 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.56 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0176 Acc: 0.9941 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.11 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0272 Acc: 0.9906 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.94 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0476 Acc: 0.9859 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.00 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0199 Acc: 0.9941 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.68 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0158 Acc: 0.9953 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.75 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0137 Acc: 0.9953 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.97 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0190 Acc: 0.9941 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.56 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0167 Acc: 0.9906 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.39 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0112 Acc: 0.9976 | Val Loss: 0.0017 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.76 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0211 Acc: 0.9941 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.57 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0175 Acc: 0.9929 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.32 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0198 Acc: 0.9953 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.75 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0078 Acc: 0.9976 | Val Loss: 0.0018 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.85 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0219 Acc: 0.9918 | Val Loss: 0.0019 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.84 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0136 Acc: 0.9976 | Val Loss: 0.0004 Acc: 1.0000 | Mem: 2754.66MB | Speed: 219.00 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0234 Acc: 0.9929 | Val Loss: 0.0005 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.03 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0204 Acc: 0.9929 | Val Loss: 0.0030 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.80 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0180 Acc: 0.9965 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.72 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0095 Acc: 0.9976 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.93 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0071 Acc: 0.9976 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.43 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0115 Acc: 0.9976 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.84 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0127 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.01 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0152 Acc: 0.9941 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.74 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0134 Acc: 0.9953 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.28 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0180 Acc: 0.9941 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.89 samples/s\n",
      "Epoch 124/1000 | Train Loss: 0.0192 Acc: 0.9906 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.93 samples/s\n",
      "Epoch 125/1000 | Train Loss: 0.0148 Acc: 0.9941 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.89 samples/s\n",
      "Epoch 126/1000 | Train Loss: 0.0111 Acc: 0.9953 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.06 samples/s\n",
      "Epoch 127/1000 | Train Loss: 0.0182 Acc: 0.9953 | Val Loss: 0.0181 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.38 samples/s\n",
      "Epoch 128/1000 | Train Loss: 0.0113 Acc: 0.9953 | Val Loss: 0.0312 Acc: 0.9884 | Mem: 2754.66MB | Speed: 217.76 samples/s\n",
      "Epoch 129/1000 | Train Loss: 0.0211 Acc: 0.9918 | Val Loss: 0.0049 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.56 samples/s\n",
      "Epoch 130/1000 | Train Loss: 0.0167 Acc: 0.9976 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.54 samples/s\n",
      "Epoch 131/1000 | Train Loss: 0.0110 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.82 samples/s\n",
      "Epoch 132/1000 | Train Loss: 0.0098 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2754.66MB | Speed: 217.57 samples/s\n",
      "Epoch 133/1000 | Train Loss: 0.0096 Acc: 0.9976 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.21 samples/s\n",
      "Epoch 134/1000 | Train Loss: 0.0164 Acc: 0.9941 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.72 samples/s\n",
      "Epoch 135/1000 | Train Loss: 0.0087 Acc: 0.9953 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.83 samples/s\n",
      "Epoch 136/1000 | Train Loss: 0.0227 Acc: 0.9929 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2754.66MB | Speed: 218.05 samples/s\n",
      "Epoch 137/1000 | Train Loss: 0.0100 Acc: 0.9965 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2754.66MB | Speed: 216.68 samples/s\n",
      "Stopping early at epoch 137 (no improvement in 100 epochs).\n",
      "Subject 7 final accuracy: 0.8715\n",
      "seed is 489\n",
      "Subject 8\n",
      "Epoch 1/1000 | Train Loss: 1.1739 Acc: 0.5024 | Val Loss: 0.9930 Acc: 0.5930 | Mem: 2764.13MB | Speed: 216.10 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.7589 Acc: 0.7129 | Val Loss: 1.1260 Acc: 0.6047 | Mem: 2764.13MB | Speed: 216.89 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.5518 Acc: 0.8012 | Val Loss: 1.1723 Acc: 0.6628 | Mem: 2764.13MB | Speed: 216.69 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.4347 Acc: 0.8412 | Val Loss: 0.9390 Acc: 0.7442 | Mem: 2754.24MB | Speed: 216.48 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.3586 Acc: 0.8612 | Val Loss: 0.5775 Acc: 0.8140 | Mem: 2754.30MB | Speed: 216.01 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.2707 Acc: 0.9012 | Val Loss: 0.3671 Acc: 0.8605 | Mem: 2754.24MB | Speed: 216.42 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.2426 Acc: 0.9094 | Val Loss: 0.2380 Acc: 0.9186 | Mem: 2754.30MB | Speed: 216.46 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.1968 Acc: 0.9306 | Val Loss: 0.1587 Acc: 0.9651 | Mem: 2754.24MB | Speed: 216.72 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.1523 Acc: 0.9482 | Val Loss: 0.1164 Acc: 0.9651 | Mem: 2754.30MB | Speed: 215.69 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.1656 Acc: 0.9482 | Val Loss: 0.1138 Acc: 0.9535 | Mem: 2754.24MB | Speed: 216.00 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.1471 Acc: 0.9447 | Val Loss: 0.0783 Acc: 0.9535 | Mem: 2754.30MB | Speed: 215.76 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.1501 Acc: 0.9388 | Val Loss: 0.0701 Acc: 0.9535 | Mem: 2754.24MB | Speed: 216.11 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.1261 Acc: 0.9612 | Val Loss: 0.0678 Acc: 0.9651 | Mem: 2754.30MB | Speed: 216.81 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.1031 Acc: 0.9671 | Val Loss: 0.0766 Acc: 0.9651 | Mem: 2754.24MB | Speed: 216.12 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.1073 Acc: 0.9635 | Val Loss: 0.0877 Acc: 0.9651 | Mem: 2754.30MB | Speed: 216.91 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.0780 Acc: 0.9729 | Val Loss: 0.1158 Acc: 0.9651 | Mem: 2754.24MB | Speed: 215.83 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.0977 Acc: 0.9624 | Val Loss: 0.1051 Acc: 0.9651 | Mem: 2754.30MB | Speed: 216.36 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.1012 Acc: 0.9635 | Val Loss: 0.1110 Acc: 0.9651 | Mem: 2754.24MB | Speed: 215.87 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.0813 Acc: 0.9706 | Val Loss: 0.0851 Acc: 0.9651 | Mem: 2754.30MB | Speed: 215.98 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.0877 Acc: 0.9659 | Val Loss: 0.0418 Acc: 0.9767 | Mem: 2754.24MB | Speed: 215.80 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.0982 Acc: 0.9624 | Val Loss: 0.0323 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.67 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.0643 Acc: 0.9788 | Val Loss: 0.0348 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.01 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.0598 Acc: 0.9788 | Val Loss: 0.0478 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.63 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.0538 Acc: 0.9800 | Val Loss: 0.0641 Acc: 0.9884 | Mem: 2754.24MB | Speed: 217.11 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.0565 Acc: 0.9824 | Val Loss: 0.0555 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.21 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.0514 Acc: 0.9824 | Val Loss: 0.0383 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.81 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.0575 Acc: 0.9847 | Val Loss: 0.0244 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.41 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.0402 Acc: 0.9894 | Val Loss: 0.0314 Acc: 0.9884 | Mem: 2754.24MB | Speed: 214.98 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.0583 Acc: 0.9812 | Val Loss: 0.0284 Acc: 0.9767 | Mem: 2754.30MB | Speed: 215.66 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.0616 Acc: 0.9835 | Val Loss: 0.0251 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.17 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0601 Acc: 0.9776 | Val Loss: 0.0283 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.53 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.0379 Acc: 0.9882 | Val Loss: 0.0293 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.58 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0566 Acc: 0.9824 | Val Loss: 0.0176 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.40 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0576 Acc: 0.9765 | Val Loss: 0.0282 Acc: 0.9884 | Mem: 2754.24MB | Speed: 215.35 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0459 Acc: 0.9882 | Val Loss: 0.0242 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.47 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0606 Acc: 0.9812 | Val Loss: 0.0567 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.48 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0422 Acc: 0.9871 | Val Loss: 0.0494 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.22 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0486 Acc: 0.9800 | Val Loss: 0.0471 Acc: 0.9651 | Mem: 2754.24MB | Speed: 216.94 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0303 Acc: 0.9906 | Val Loss: 0.0589 Acc: 0.9651 | Mem: 2754.30MB | Speed: 215.74 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0357 Acc: 0.9835 | Val Loss: 0.0411 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.01 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0416 Acc: 0.9835 | Val Loss: 0.0334 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.39 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0290 Acc: 0.9929 | Val Loss: 0.0590 Acc: 0.9651 | Mem: 2754.24MB | Speed: 215.90 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0418 Acc: 0.9871 | Val Loss: 0.0925 Acc: 0.9651 | Mem: 2754.30MB | Speed: 216.79 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0331 Acc: 0.9929 | Val Loss: 0.0569 Acc: 0.9651 | Mem: 2754.24MB | Speed: 216.61 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0305 Acc: 0.9906 | Val Loss: 0.0271 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.39 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0343 Acc: 0.9859 | Val Loss: 0.0228 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.25 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0208 Acc: 0.9941 | Val Loss: 0.0470 Acc: 0.9651 | Mem: 2754.30MB | Speed: 216.46 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0207 Acc: 0.9929 | Val Loss: 0.0655 Acc: 0.9767 | Mem: 2754.24MB | Speed: 215.65 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0212 Acc: 0.9941 | Val Loss: 0.0616 Acc: 0.9767 | Mem: 2754.30MB | Speed: 215.80 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0488 Acc: 0.9824 | Val Loss: 0.0839 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.31 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0389 Acc: 0.9882 | Val Loss: 0.1133 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.26 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0377 Acc: 0.9859 | Val Loss: 0.0973 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.28 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0452 Acc: 0.9812 | Val Loss: 0.0380 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.36 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0457 Acc: 0.9812 | Val Loss: 0.0538 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.25 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0207 Acc: 0.9918 | Val Loss: 0.0402 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.56 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0360 Acc: 0.9871 | Val Loss: 0.0413 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.75 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0397 Acc: 0.9847 | Val Loss: 0.0620 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.16 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0376 Acc: 0.9835 | Val Loss: 0.0340 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.16 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0295 Acc: 0.9894 | Val Loss: 0.0498 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.17 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0325 Acc: 0.9859 | Val Loss: 0.1013 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.41 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0328 Acc: 0.9882 | Val Loss: 0.0791 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.97 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0334 Acc: 0.9882 | Val Loss: 0.0444 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.57 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0303 Acc: 0.9882 | Val Loss: 0.0593 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.27 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0403 Acc: 0.9871 | Val Loss: 0.0969 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.79 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0244 Acc: 0.9929 | Val Loss: 0.1003 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.39 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0347 Acc: 0.9871 | Val Loss: 0.0298 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.23 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0328 Acc: 0.9906 | Val Loss: 0.0110 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.36 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0370 Acc: 0.9859 | Val Loss: 0.0434 Acc: 0.9884 | Mem: 2754.24MB | Speed: 215.98 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0269 Acc: 0.9906 | Val Loss: 0.0550 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.76 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0227 Acc: 0.9965 | Val Loss: 0.0424 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.62 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0339 Acc: 0.9859 | Val Loss: 0.0047 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.87 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0376 Acc: 0.9871 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2754.24MB | Speed: 216.07 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0373 Acc: 0.9871 | Val Loss: 0.0041 Acc: 1.0000 | Mem: 2754.30MB | Speed: 215.90 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0208 Acc: 0.9929 | Val Loss: 0.0428 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.22 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0386 Acc: 0.9859 | Val Loss: 0.0414 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.97 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0317 Acc: 0.9871 | Val Loss: 0.0218 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.10 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0286 Acc: 0.9906 | Val Loss: 0.0213 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.95 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0270 Acc: 0.9906 | Val Loss: 0.0378 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.79 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0269 Acc: 0.9871 | Val Loss: 0.0217 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.38 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0306 Acc: 0.9894 | Val Loss: 0.0390 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.46 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0307 Acc: 0.9835 | Val Loss: 0.0380 Acc: 0.9884 | Mem: 2754.30MB | Speed: 218.19 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0374 Acc: 0.9882 | Val Loss: 0.0363 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.29 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0250 Acc: 0.9894 | Val Loss: 0.0215 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.65 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0288 Acc: 0.9894 | Val Loss: 0.0093 Acc: 1.0000 | Mem: 2754.24MB | Speed: 216.59 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0256 Acc: 0.9882 | Val Loss: 0.0098 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.72 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0167 Acc: 0.9965 | Val Loss: 0.0154 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.59 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0428 Acc: 0.9918 | Val Loss: 0.0172 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.55 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0241 Acc: 0.9906 | Val Loss: 0.0335 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.67 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0197 Acc: 0.9953 | Val Loss: 0.0450 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.89 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0207 Acc: 0.9918 | Val Loss: 0.0674 Acc: 0.9884 | Mem: 2754.24MB | Speed: 217.30 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0252 Acc: 0.9906 | Val Loss: 0.0702 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.30 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0159 Acc: 0.9941 | Val Loss: 0.0661 Acc: 0.9767 | Mem: 2754.24MB | Speed: 218.03 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0242 Acc: 0.9882 | Val Loss: 0.0340 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.48 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0166 Acc: 0.9906 | Val Loss: 0.0015 Acc: 1.0000 | Mem: 2754.24MB | Speed: 216.19 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0242 Acc: 0.9918 | Val Loss: 0.0061 Acc: 1.0000 | Mem: 2754.30MB | Speed: 216.01 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0199 Acc: 0.9918 | Val Loss: 0.0055 Acc: 1.0000 | Mem: 2754.24MB | Speed: 217.16 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0282 Acc: 0.9929 | Val Loss: 0.0211 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.30 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0198 Acc: 0.9918 | Val Loss: 0.0208 Acc: 0.9884 | Mem: 2754.24MB | Speed: 217.13 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0271 Acc: 0.9906 | Val Loss: 0.0439 Acc: 0.9884 | Mem: 2754.30MB | Speed: 216.33 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0233 Acc: 0.9906 | Val Loss: 0.0468 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.91 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0246 Acc: 0.9941 | Val Loss: 0.0470 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.32 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0337 Acc: 0.9871 | Val Loss: 0.0459 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.03 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0191 Acc: 0.9953 | Val Loss: 0.0199 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.97 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0285 Acc: 0.9894 | Val Loss: 0.0112 Acc: 0.9884 | Mem: 2754.24MB | Speed: 217.52 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0313 Acc: 0.9871 | Val Loss: 0.0767 Acc: 0.9884 | Mem: 2754.30MB | Speed: 215.45 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0333 Acc: 0.9882 | Val Loss: 0.0804 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.85 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0367 Acc: 0.9882 | Val Loss: 0.0578 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.56 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0110 Acc: 0.9976 | Val Loss: 0.0664 Acc: 0.9884 | Mem: 2754.24MB | Speed: 217.16 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0250 Acc: 0.9906 | Val Loss: 0.0622 Acc: 0.9884 | Mem: 2754.30MB | Speed: 217.45 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0205 Acc: 0.9906 | Val Loss: 0.0579 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.48 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0163 Acc: 0.9953 | Val Loss: 0.0796 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.78 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0209 Acc: 0.9918 | Val Loss: 0.0578 Acc: 0.9767 | Mem: 2754.24MB | Speed: 217.97 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0178 Acc: 0.9918 | Val Loss: 0.0333 Acc: 0.9767 | Mem: 2754.30MB | Speed: 217.43 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0291 Acc: 0.9894 | Val Loss: 0.0646 Acc: 0.9767 | Mem: 2754.24MB | Speed: 216.50 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0296 Acc: 0.9929 | Val Loss: 0.0687 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.13 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0284 Acc: 0.9929 | Val Loss: 0.0280 Acc: 0.9884 | Mem: 2754.24MB | Speed: 216.19 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0243 Acc: 0.9894 | Val Loss: 0.0245 Acc: 0.9767 | Mem: 2754.30MB | Speed: 216.66 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0305 Acc: 0.9871 | Val Loss: 0.0148 Acc: 0.9884 | Mem: 2754.24MB | Speed: 215.62 samples/s\n",
      "Stopping early at epoch 118 (no improvement in 100 epochs).\n",
      "Subject 8 final accuracy: 0.7986\n",
      "seed is 1097\n",
      "Subject 9\n",
      "Epoch 1/1000 | Train Loss: 1.1872 Acc: 0.4800 | Val Loss: 0.7709 Acc: 0.6860 | Mem: 2755.46MB | Speed: 216.41 samples/s\n",
      "Epoch 2/1000 | Train Loss: 0.7168 Acc: 0.7118 | Val Loss: 1.3083 Acc: 0.5930 | Mem: 2756.22MB | Speed: 216.16 samples/s\n",
      "Epoch 3/1000 | Train Loss: 0.5580 Acc: 0.7824 | Val Loss: 1.3504 Acc: 0.6512 | Mem: 2756.22MB | Speed: 217.26 samples/s\n",
      "Epoch 4/1000 | Train Loss: 0.4283 Acc: 0.8412 | Val Loss: 1.0190 Acc: 0.7093 | Mem: 2756.22MB | Speed: 216.21 samples/s\n",
      "Epoch 5/1000 | Train Loss: 0.3126 Acc: 0.8847 | Val Loss: 0.6076 Acc: 0.8023 | Mem: 2756.22MB | Speed: 217.27 samples/s\n",
      "Epoch 6/1000 | Train Loss: 0.2754 Acc: 0.8988 | Val Loss: 0.3735 Acc: 0.8605 | Mem: 2756.22MB | Speed: 215.62 samples/s\n",
      "Epoch 7/1000 | Train Loss: 0.2233 Acc: 0.9188 | Val Loss: 0.2612 Acc: 0.8721 | Mem: 2756.22MB | Speed: 215.72 samples/s\n",
      "Epoch 8/1000 | Train Loss: 0.1831 Acc: 0.9353 | Val Loss: 0.1750 Acc: 0.9535 | Mem: 2756.22MB | Speed: 217.35 samples/s\n",
      "Epoch 9/1000 | Train Loss: 0.1898 Acc: 0.9224 | Val Loss: 0.0887 Acc: 0.9767 | Mem: 2756.22MB | Speed: 215.79 samples/s\n",
      "Epoch 10/1000 | Train Loss: 0.1710 Acc: 0.9329 | Val Loss: 0.0985 Acc: 0.9535 | Mem: 2756.22MB | Speed: 215.47 samples/s\n",
      "Epoch 11/1000 | Train Loss: 0.1379 Acc: 0.9482 | Val Loss: 0.0971 Acc: 0.9535 | Mem: 2756.22MB | Speed: 216.27 samples/s\n",
      "Epoch 12/1000 | Train Loss: 0.1106 Acc: 0.9600 | Val Loss: 0.1020 Acc: 0.9651 | Mem: 2756.22MB | Speed: 216.61 samples/s\n",
      "Epoch 13/1000 | Train Loss: 0.1214 Acc: 0.9565 | Val Loss: 0.0746 Acc: 0.9651 | Mem: 2756.22MB | Speed: 216.38 samples/s\n",
      "Epoch 14/1000 | Train Loss: 0.0973 Acc: 0.9635 | Val Loss: 0.0598 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.20 samples/s\n",
      "Epoch 15/1000 | Train Loss: 0.1001 Acc: 0.9706 | Val Loss: 0.0480 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.23 samples/s\n",
      "Epoch 16/1000 | Train Loss: 0.0814 Acc: 0.9729 | Val Loss: 0.0290 Acc: 0.9767 | Mem: 2756.22MB | Speed: 217.73 samples/s\n",
      "Epoch 17/1000 | Train Loss: 0.0791 Acc: 0.9765 | Val Loss: 0.0434 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.12 samples/s\n",
      "Epoch 18/1000 | Train Loss: 0.0766 Acc: 0.9729 | Val Loss: 0.0342 Acc: 0.9767 | Mem: 2756.22MB | Speed: 217.11 samples/s\n",
      "Epoch 19/1000 | Train Loss: 0.0745 Acc: 0.9718 | Val Loss: 0.0311 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.22 samples/s\n",
      "Epoch 20/1000 | Train Loss: 0.0747 Acc: 0.9765 | Val Loss: 0.0530 Acc: 0.9767 | Mem: 2756.22MB | Speed: 217.21 samples/s\n",
      "Epoch 21/1000 | Train Loss: 0.0684 Acc: 0.9788 | Val Loss: 0.0334 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.61 samples/s\n",
      "Epoch 22/1000 | Train Loss: 0.0608 Acc: 0.9800 | Val Loss: 0.0252 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.66 samples/s\n",
      "Epoch 23/1000 | Train Loss: 0.0539 Acc: 0.9824 | Val Loss: 0.0246 Acc: 0.9884 | Mem: 2756.22MB | Speed: 215.86 samples/s\n",
      "Epoch 24/1000 | Train Loss: 0.0501 Acc: 0.9859 | Val Loss: 0.0162 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.44 samples/s\n",
      "Epoch 25/1000 | Train Loss: 0.0618 Acc: 0.9859 | Val Loss: 0.0104 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.08 samples/s\n",
      "Epoch 26/1000 | Train Loss: 0.0464 Acc: 0.9835 | Val Loss: 0.0082 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.10 samples/s\n",
      "Epoch 27/1000 | Train Loss: 0.0396 Acc: 0.9871 | Val Loss: 0.0130 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.52 samples/s\n",
      "Epoch 28/1000 | Train Loss: 0.0401 Acc: 0.9906 | Val Loss: 0.0254 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.24 samples/s\n",
      "Epoch 29/1000 | Train Loss: 0.0364 Acc: 0.9882 | Val Loss: 0.0310 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.43 samples/s\n",
      "Epoch 30/1000 | Train Loss: 0.0547 Acc: 0.9812 | Val Loss: 0.0065 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.53 samples/s\n",
      "Epoch 31/1000 | Train Loss: 0.0340 Acc: 0.9894 | Val Loss: 0.0191 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.00 samples/s\n",
      "Epoch 32/1000 | Train Loss: 0.0483 Acc: 0.9800 | Val Loss: 0.0272 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.43 samples/s\n",
      "Epoch 33/1000 | Train Loss: 0.0235 Acc: 0.9929 | Val Loss: 0.0185 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.07 samples/s\n",
      "Epoch 34/1000 | Train Loss: 0.0424 Acc: 0.9824 | Val Loss: 0.0201 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.90 samples/s\n",
      "Epoch 35/1000 | Train Loss: 0.0342 Acc: 0.9882 | Val Loss: 0.0175 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.02 samples/s\n",
      "Epoch 36/1000 | Train Loss: 0.0394 Acc: 0.9871 | Val Loss: 0.0455 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.28 samples/s\n",
      "Epoch 37/1000 | Train Loss: 0.0459 Acc: 0.9871 | Val Loss: 0.0523 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.08 samples/s\n",
      "Epoch 38/1000 | Train Loss: 0.0371 Acc: 0.9906 | Val Loss: 0.0357 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.01 samples/s\n",
      "Epoch 39/1000 | Train Loss: 0.0400 Acc: 0.9835 | Val Loss: 0.0529 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.77 samples/s\n",
      "Epoch 40/1000 | Train Loss: 0.0331 Acc: 0.9882 | Val Loss: 0.0607 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.22 samples/s\n",
      "Epoch 41/1000 | Train Loss: 0.0291 Acc: 0.9929 | Val Loss: 0.0358 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.06 samples/s\n",
      "Epoch 42/1000 | Train Loss: 0.0376 Acc: 0.9871 | Val Loss: 0.0191 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.12 samples/s\n",
      "Epoch 43/1000 | Train Loss: 0.0361 Acc: 0.9882 | Val Loss: 0.0841 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.88 samples/s\n",
      "Epoch 44/1000 | Train Loss: 0.0298 Acc: 0.9906 | Val Loss: 0.0956 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.68 samples/s\n",
      "Epoch 45/1000 | Train Loss: 0.0270 Acc: 0.9894 | Val Loss: 0.0618 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.59 samples/s\n",
      "Epoch 46/1000 | Train Loss: 0.0258 Acc: 0.9894 | Val Loss: 0.0395 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.70 samples/s\n",
      "Epoch 47/1000 | Train Loss: 0.0288 Acc: 0.9906 | Val Loss: 0.0363 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.32 samples/s\n",
      "Epoch 48/1000 | Train Loss: 0.0288 Acc: 0.9906 | Val Loss: 0.0374 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.51 samples/s\n",
      "Epoch 49/1000 | Train Loss: 0.0184 Acc: 0.9918 | Val Loss: 0.0502 Acc: 0.9767 | Mem: 2756.22MB | Speed: 217.77 samples/s\n",
      "Epoch 50/1000 | Train Loss: 0.0412 Acc: 0.9847 | Val Loss: 0.0291 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.04 samples/s\n",
      "Epoch 51/1000 | Train Loss: 0.0366 Acc: 0.9871 | Val Loss: 0.0184 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.32 samples/s\n",
      "Epoch 52/1000 | Train Loss: 0.0331 Acc: 0.9871 | Val Loss: 0.0093 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.44 samples/s\n",
      "Epoch 53/1000 | Train Loss: 0.0349 Acc: 0.9894 | Val Loss: 0.0272 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.44 samples/s\n",
      "Epoch 54/1000 | Train Loss: 0.0480 Acc: 0.9859 | Val Loss: 0.0372 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.59 samples/s\n",
      "Epoch 55/1000 | Train Loss: 0.0360 Acc: 0.9882 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.34 samples/s\n",
      "Epoch 56/1000 | Train Loss: 0.0301 Acc: 0.9906 | Val Loss: 0.0011 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.75 samples/s\n",
      "Epoch 57/1000 | Train Loss: 0.0412 Acc: 0.9776 | Val Loss: 0.0048 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.37 samples/s\n",
      "Epoch 58/1000 | Train Loss: 0.0329 Acc: 0.9847 | Val Loss: 0.0009 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.26 samples/s\n",
      "Epoch 59/1000 | Train Loss: 0.0314 Acc: 0.9871 | Val Loss: 0.0067 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.18 samples/s\n",
      "Epoch 60/1000 | Train Loss: 0.0272 Acc: 0.9941 | Val Loss: 0.0022 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.45 samples/s\n",
      "Epoch 61/1000 | Train Loss: 0.0338 Acc: 0.9859 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.91 samples/s\n",
      "Epoch 62/1000 | Train Loss: 0.0238 Acc: 0.9906 | Val Loss: 0.0022 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.15 samples/s\n",
      "Epoch 63/1000 | Train Loss: 0.0374 Acc: 0.9871 | Val Loss: 0.0073 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.68 samples/s\n",
      "Epoch 64/1000 | Train Loss: 0.0235 Acc: 0.9941 | Val Loss: 0.0062 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.98 samples/s\n",
      "Epoch 65/1000 | Train Loss: 0.0179 Acc: 0.9918 | Val Loss: 0.0082 Acc: 0.9884 | Mem: 2756.22MB | Speed: 215.47 samples/s\n",
      "Epoch 66/1000 | Train Loss: 0.0110 Acc: 0.9976 | Val Loss: 0.0029 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.67 samples/s\n",
      "Epoch 67/1000 | Train Loss: 0.0215 Acc: 0.9941 | Val Loss: 0.0126 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.91 samples/s\n",
      "Epoch 68/1000 | Train Loss: 0.0255 Acc: 0.9906 | Val Loss: 0.0568 Acc: 0.9767 | Mem: 2756.22MB | Speed: 217.20 samples/s\n",
      "Epoch 69/1000 | Train Loss: 0.0238 Acc: 0.9929 | Val Loss: 0.0241 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.43 samples/s\n",
      "Epoch 70/1000 | Train Loss: 0.0106 Acc: 0.9953 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.68 samples/s\n",
      "Epoch 71/1000 | Train Loss: 0.0164 Acc: 0.9941 | Val Loss: 0.0099 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.19 samples/s\n",
      "Epoch 72/1000 | Train Loss: 0.0165 Acc: 0.9941 | Val Loss: 0.0142 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.75 samples/s\n",
      "Epoch 73/1000 | Train Loss: 0.0367 Acc: 0.9894 | Val Loss: 0.0025 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.31 samples/s\n",
      "Epoch 74/1000 | Train Loss: 0.0223 Acc: 0.9906 | Val Loss: 0.0107 Acc: 0.9884 | Mem: 2756.22MB | Speed: 215.74 samples/s\n",
      "Epoch 75/1000 | Train Loss: 0.0303 Acc: 0.9918 | Val Loss: 0.0209 Acc: 0.9884 | Mem: 2756.22MB | Speed: 215.76 samples/s\n",
      "Epoch 76/1000 | Train Loss: 0.0214 Acc: 0.9918 | Val Loss: 0.0022 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.92 samples/s\n",
      "Epoch 77/1000 | Train Loss: 0.0154 Acc: 0.9953 | Val Loss: 0.0012 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.36 samples/s\n",
      "Epoch 78/1000 | Train Loss: 0.0128 Acc: 0.9965 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.57 samples/s\n",
      "Epoch 79/1000 | Train Loss: 0.0188 Acc: 0.9918 | Val Loss: 0.0013 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.98 samples/s\n",
      "Epoch 80/1000 | Train Loss: 0.0124 Acc: 0.9953 | Val Loss: 0.0187 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.28 samples/s\n",
      "Epoch 81/1000 | Train Loss: 0.0237 Acc: 0.9918 | Val Loss: 0.0165 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.65 samples/s\n",
      "Epoch 82/1000 | Train Loss: 0.0191 Acc: 0.9918 | Val Loss: 0.0581 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.04 samples/s\n",
      "Epoch 83/1000 | Train Loss: 0.0276 Acc: 0.9941 | Val Loss: 0.0030 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.51 samples/s\n",
      "Epoch 84/1000 | Train Loss: 0.0300 Acc: 0.9882 | Val Loss: 0.0187 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.24 samples/s\n",
      "Epoch 85/1000 | Train Loss: 0.0122 Acc: 0.9965 | Val Loss: 0.0557 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.67 samples/s\n",
      "Epoch 86/1000 | Train Loss: 0.0331 Acc: 0.9882 | Val Loss: 0.0016 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.14 samples/s\n",
      "Epoch 87/1000 | Train Loss: 0.0303 Acc: 0.9871 | Val Loss: 0.0200 Acc: 0.9884 | Mem: 2756.22MB | Speed: 215.50 samples/s\n",
      "Epoch 88/1000 | Train Loss: 0.0176 Acc: 0.9929 | Val Loss: 0.0072 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.56 samples/s\n",
      "Epoch 89/1000 | Train Loss: 0.0141 Acc: 0.9953 | Val Loss: 0.0059 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.77 samples/s\n",
      "Epoch 90/1000 | Train Loss: 0.0127 Acc: 0.9965 | Val Loss: 0.0066 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.22 samples/s\n",
      "Epoch 91/1000 | Train Loss: 0.0131 Acc: 0.9941 | Val Loss: 0.0031 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.83 samples/s\n",
      "Epoch 92/1000 | Train Loss: 0.0243 Acc: 0.9906 | Val Loss: 0.0630 Acc: 0.9535 | Mem: 2756.22MB | Speed: 216.31 samples/s\n",
      "Epoch 93/1000 | Train Loss: 0.0181 Acc: 0.9929 | Val Loss: 0.0713 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.91 samples/s\n",
      "Epoch 94/1000 | Train Loss: 0.0074 Acc: 0.9976 | Val Loss: 0.0655 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.93 samples/s\n",
      "Epoch 95/1000 | Train Loss: 0.0314 Acc: 0.9882 | Val Loss: 0.0486 Acc: 0.9884 | Mem: 2756.22MB | Speed: 217.81 samples/s\n",
      "Epoch 96/1000 | Train Loss: 0.0164 Acc: 0.9929 | Val Loss: 0.0027 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.34 samples/s\n",
      "Epoch 97/1000 | Train Loss: 0.0144 Acc: 0.9953 | Val Loss: 0.0678 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.59 samples/s\n",
      "Epoch 98/1000 | Train Loss: 0.0223 Acc: 0.9941 | Val Loss: 0.0378 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.39 samples/s\n",
      "Epoch 99/1000 | Train Loss: 0.0155 Acc: 0.9929 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.13 samples/s\n",
      "Epoch 100/1000 | Train Loss: 0.0139 Acc: 0.9953 | Val Loss: 0.0081 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.91 samples/s\n",
      "Epoch 101/1000 | Train Loss: 0.0286 Acc: 0.9871 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.85 samples/s\n",
      "Epoch 102/1000 | Train Loss: 0.0244 Acc: 0.9894 | Val Loss: 0.0461 Acc: 0.9767 | Mem: 2756.22MB | Speed: 216.35 samples/s\n",
      "Epoch 103/1000 | Train Loss: 0.0236 Acc: 0.9894 | Val Loss: 0.0562 Acc: 0.9884 | Mem: 2756.22MB | Speed: 216.40 samples/s\n",
      "Epoch 104/1000 | Train Loss: 0.0250 Acc: 0.9906 | Val Loss: 0.0050 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.17 samples/s\n",
      "Epoch 105/1000 | Train Loss: 0.0177 Acc: 0.9965 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.68 samples/s\n",
      "Epoch 106/1000 | Train Loss: 0.0123 Acc: 0.9941 | Val Loss: 0.0007 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.00 samples/s\n",
      "Epoch 107/1000 | Train Loss: 0.0116 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.08 samples/s\n",
      "Epoch 108/1000 | Train Loss: 0.0154 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.90 samples/s\n",
      "Epoch 109/1000 | Train Loss: 0.0042 Acc: 1.0000 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.92 samples/s\n",
      "Epoch 110/1000 | Train Loss: 0.0188 Acc: 0.9929 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.34 samples/s\n",
      "Epoch 111/1000 | Train Loss: 0.0112 Acc: 0.9953 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.66 samples/s\n",
      "Epoch 112/1000 | Train Loss: 0.0190 Acc: 0.9941 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.53 samples/s\n",
      "Epoch 113/1000 | Train Loss: 0.0127 Acc: 0.9953 | Val Loss: 0.0002 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.61 samples/s\n",
      "Epoch 114/1000 | Train Loss: 0.0143 Acc: 0.9929 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.59 samples/s\n",
      "Epoch 115/1000 | Train Loss: 0.0079 Acc: 0.9976 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.13 samples/s\n",
      "Epoch 116/1000 | Train Loss: 0.0293 Acc: 0.9906 | Val Loss: 0.0027 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.83 samples/s\n",
      "Epoch 117/1000 | Train Loss: 0.0082 Acc: 0.9965 | Val Loss: 0.0006 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.78 samples/s\n",
      "Epoch 118/1000 | Train Loss: 0.0255 Acc: 0.9894 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.96 samples/s\n",
      "Epoch 119/1000 | Train Loss: 0.0151 Acc: 0.9941 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2756.22MB | Speed: 216.77 samples/s\n",
      "Epoch 120/1000 | Train Loss: 0.0103 Acc: 0.9953 | Val Loss: 0.0001 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.64 samples/s\n",
      "Epoch 121/1000 | Train Loss: 0.0262 Acc: 0.9929 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 217.09 samples/s\n",
      "Epoch 122/1000 | Train Loss: 0.0084 Acc: 0.9965 | Val Loss: 0.0000 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.63 samples/s\n",
      "Epoch 123/1000 | Train Loss: 0.0224 Acc: 0.9941 | Val Loss: 0.0003 Acc: 1.0000 | Mem: 2756.22MB | Speed: 215.68 samples/s\n",
      "Stopping early at epoch 123 (no improvement in 100 epochs).\n",
      "Subject 9 final accuracy: 0.8229\n",
      "Average accuracy: 0.7577160493827161\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "CTNet-Mamba: A Convolution-Mamba Network for EEG-Based Motor Imagery Classification\n",
    "\n",
    "author: zhaowei701@163.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from zeta.nn import MultiQueryAttention\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.backends import cudnn\n",
    "from torchsummary import summary\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from utils import load_data_evaluate, numberClassChannel, calMetrics\n",
    "\n",
    "# Try to import real MambaBlock (fallback if missing)\n",
    "try:\n",
    "    from mamba_ssm import Mamba\n",
    "except ImportError:\n",
    "    class Mamba(nn.Module):\n",
    "        def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "            super().__init__()\n",
    "            self.linear = nn.Linear(d_model, d_model)\n",
    "        def forward(self, x):\n",
    "            return self.linear(x)\n",
    "\n",
    "from zeta.nn import MambaBlock, FeedForward, MultiQueryAttention\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PatchEmbeddingCNN\n",
    "# -----------------------------------------------------------------------------\n",
    "class PatchEmbeddingCNN(nn.Module):\n",
    "    def __init__(self, f1=16, kernel_size=64, D=2,\n",
    "                 pooling_size1=8, pooling_size2=8,\n",
    "                 dropout_rate=0.3, number_channel=22, emb_size=40):\n",
    "        super().__init__()\n",
    "        f2 = D * f1\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, (1, kernel_size), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.Conv2d(f1, f2, (number_channel, 1), groups=f1, bias=False),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pooling_size1)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(f2, f2, (1, 16), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pooling_size2)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.projection = Rearrange('b e h w -> b (h w) e')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_module(x)        # [B, f2, 1, seq]\n",
    "        return self.projection(x)     # [B, seq, f2]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# LinearAttention\n",
    "# -----------------------------------------------------------------------------\n",
    "def exists(val): return val is not None\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, *, heads=4, dim_head=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        inner = heads * dim_head\n",
    "        self.heads, self.scale = heads, dim_head**-0.5\n",
    "        self.to_qkv = nn.Linear(dim, inner*3, bias=False)\n",
    "        self.to_out = nn.Sequential(nn.Linear(inner, dim), nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        h = self.heads\n",
    "        q,k,v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q,k,v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=h), (q,k,v))\n",
    "        q, k = q*self.scale, k\n",
    "        q, k = q.softmax(dim=-1), k.softmax(dim=-2)\n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, 'b n -> (b h) n', h=h)\n",
    "            k = k.masked_fill(~mask.unsqueeze(-1), 0.)\n",
    "        ctx = torch.einsum('b n d, b n e -> b d e', q, k)\n",
    "        out = torch.einsum('b d e, b n d -> b n e', ctx, v)\n",
    "        out = rearrange(out, '(b h) n d -> b n (h d)', h=h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TransformerBlock\n",
    "# -----------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MambaTransformerblock(nn.Module):\n",
    "    def __init__(self, dim, heads, dim_head, dropout=0.1, \n",
    "                 ff_mult=4, d_state=16, depth=4):        \n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            self._create_layer(dim, heads, ff_mult, d_state, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def _create_layer(self, dim, heads, ff_mult, d_state, dropout):\n",
    "        return nn.ModuleDict({\n",
    "            # 1) Mamba\n",
    "            'mamba_norm':   nn.LayerNorm(dim),\n",
    "            'mamba':        MambaBlock(dim, d_state=d_state),\n",
    "            'mamba_dropout':nn.Dropout(dropout),\n",
    "\n",
    "            # 2) PyTorch MultiheadAttention\n",
    "            'attn_norm':    nn.LayerNorm(dim),\n",
    "            'attn':         nn.MultiheadAttention(embed_dim=dim,\n",
    "                                                  num_heads=heads,\n",
    "                                                  dropout=dropout,\n",
    "                                                  batch_first=True),\n",
    "            'attn_dropout': nn.Dropout(dropout),\n",
    "\n",
    "            # 3) FFN\n",
    "            'ffn_norm':     nn.LayerNorm(dim),\n",
    "            'feedforward':  nn.Sequential(\n",
    "                                 nn.Linear(dim, ff_mult * dim),\n",
    "                                 nn.GELU(),\n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(ff_mult * dim, dim)\n",
    "                             ),\n",
    "            'ffn_dropout':  nn.Dropout(dropout),\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, dim]\n",
    "        for layer in self.layers:\n",
    "            # (1) Mamba sublayer\n",
    "            m = layer['mamba_norm'](x)\n",
    "            x = x + layer['mamba_dropout'](layer['mamba'](m))\n",
    "\n",
    "            # (2) Multi-head self-attention sublayer\n",
    "            a = layer['attn_norm'](x)\n",
    "            # because of the monkey-patch, this returns a Tensor directly\n",
    "            attn_out = layer['attn'](a, a, a, need_weights=False)\n",
    "            x = x + layer['attn_dropout'](attn_out)\n",
    "\n",
    "            # (3) Feed-forward sublayer\n",
    "            f = layer['ffn_norm'](x)\n",
    "            x = x + layer['ffn_dropout'](layer['feedforward'](f))\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# EEGMambaTransformer\n",
    "# -----------------------------------------------------------------------------\n",
    "class EEGMambaTransformer(nn.Module):\n",
    "    def __init__(self, emb_size=40, depth=6, heads=4,\n",
    "                 d_state=16, transformer_depth=1, mamba_depth=3,\n",
    "                 database_type='A', eeg1_f1=8, eeg1_kernel_size=64,\n",
    "                 eeg1_D=2, eeg1_pooling_size1=8, eeg1_pooling_size2=8,\n",
    "                 eeg1_dropout_rate=0.5, flatten_eeg1=15*16):\n",
    "        super().__init__()\n",
    "        self.number_class, self.number_channel = numberClassChannel(database_type)\n",
    "\n",
    "        self.cnn = PatchEmbeddingCNN(\n",
    "            f1=eeg1_f1, kernel_size=eeg1_kernel_size,\n",
    "            D=eeg1_D, pooling_size1=eeg1_pooling_size1,\n",
    "            pooling_size2=eeg1_pooling_size2,\n",
    "            dropout_rate=eeg1_dropout_rate,\n",
    "            number_channel=self.number_channel,\n",
    "            emb_size=emb_size\n",
    "        )\n",
    "\n",
    "        dim_head = emb_size // heads\n",
    "\n",
    "        self.mamba_transformer = MambaTransformerblock(\n",
    "            dim=emb_size, heads=heads,\n",
    "            dim_head=dim_head,\n",
    "            dropout=eeg1_dropout_rate, ff_mult=4,\n",
    "            d_state=d_state,\n",
    "            depth = depth,\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(flatten_eeg1, self.number_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)                       # [B, seq, emb]\n",
    "        x = x * np.sqrt(x.shape[-1])\n",
    "        x = self.mamba_transformer(x)\n",
    "        return x, self.classification(self.flatten(x))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Experiment wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "class ExP:\n",
    "    def __init__(self, nsub, data_dir, result_name,\n",
    "                 epochs=300, number_aug=3, number_seg=8,\n",
    "                 evaluate_mode='subject-dependent',\n",
    "                 heads=2, emb_size=16, depth=6,\n",
    "                 d_state=16, transformer_depth=1, mamba_depth=3,\n",
    "                 dataset_type='A', eeg1_f1=8, eeg1_kernel_size=64,\n",
    "                 eeg1_D=2, eeg1_pooling_size1=8, eeg1_pooling_size2=8,\n",
    "                 eeg1_dropout_rate=0.5, flatten_eeg1=15*16,\n",
    "                 validate_ratio=0.3, learning_rate=1e-3, batch_size=72,\n",
    "                 early_stopping_patience=100 ):\n",
    "        self.nSub = nsub\n",
    "        self.dataset_type = dataset_type\n",
    "        self.data_dir = data_dir\n",
    "        self.result_name = result_name\n",
    "        self.n_epochs = epochs\n",
    "        self.patience = early_stopping_patience\n",
    "        self.no_improve = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.batch_size = batch_size\n",
    "        self.validate_ratio = validate_ratio\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = EEGMambaTransformer(\n",
    "            emb_size=emb_size, depth=depth, heads=heads,\n",
    "            d_state=d_state,\n",
    "            transformer_depth=transformer_depth,\n",
    "            mamba_depth=mamba_depth,\n",
    "            database_type=dataset_type,\n",
    "            eeg1_f1=eeg1_f1, eeg1_kernel_size=eeg1_kernel_size,\n",
    "            eeg1_D=eeg1_D, eeg1_pooling_size1=eeg1_pooling_size1,\n",
    "            eeg1_pooling_size2=eeg1_pooling_size2,\n",
    "            eeg1_dropout_rate=eeg1_dropout_rate,\n",
    "            flatten_eeg1=flatten_eeg1\n",
    "        ).cuda()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        os.makedirs(self.result_name, exist_ok=True)\n",
    "        self.model_filename = os.path.join(self.result_name, f\"model_{self.nSub}.pth\")\n",
    "\n",
    "    def interaug(self, timg, label):\n",
    "        aug_data, aug_label = [], []\n",
    "        recs = 3 * (self.batch_size // self.model.number_class)\n",
    "        segpts = 1000 // 8\n",
    "        for cls in range(self.model.number_class):\n",
    "            idx = np.where(label == cls + 1)\n",
    "            data, lbl = timg[idx], label[idx]\n",
    "            tmp = np.zeros((recs,1,self.model.number_channel,1000), dtype=np.float32)\n",
    "            for i in range(recs):\n",
    "                for j in range(8):\n",
    "                    ridx = random.randrange(data.shape[0])\n",
    "                    tmp[i,0,:,j*segpts:(j+1)*segpts] = data[ridx,0,:,j*segpts:(j+1)*segpts]\n",
    "            aug_data.append(tmp); aug_label.append(lbl[:recs])\n",
    "        aug_data = np.concatenate(aug_data).astype(np.float32)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        perm = np.random.permutation(len(aug_data))\n",
    "        return (\n",
    "            torch.from_numpy(aug_data[perm]).cuda(),\n",
    "            torch.from_numpy((aug_label[perm]-1)).long().cuda()\n",
    "        )\n",
    "\n",
    "    def get_source_data(self):\n",
    "        tr_x, tr_y, te_x, te_y = load_data_evaluate(\n",
    "            self.data_dir, self.dataset_type, self.nSub,\n",
    "            mode_evaluate='subject-dependent'\n",
    "        )\n",
    "        tr_x = np.expand_dims(tr_x, axis=1).astype(np.float32)\n",
    "        te_x = np.expand_dims(te_x, axis=1).astype(np.float32)\n",
    "        tr_y = tr_y.reshape(-1)\n",
    "        te_y = te_y.reshape(-1)\n",
    "        m, s = tr_x.mean(), tr_x.std()\n",
    "        tr_x = (tr_x - m) / s\n",
    "        te_x = (te_x - m) / s\n",
    "        return tr_x, tr_y, te_x, te_y\n",
    "\n",
    "    def train(self):\n",
    "        tr_x, tr_y, te_x, te_y = self.get_source_data()\n",
    "    \n",
    "        # Create validation split\n",
    "        dataset_size = len(tr_x)\n",
    "        val_size = int(self.validate_ratio * dataset_size)\n",
    "        train_size = dataset_size - val_size\n",
    "        train_ds, val_ds = torch.utils.data.random_split(\n",
    "            torch.utils.data.TensorDataset(torch.from_numpy(tr_x), torch.from_numpy(tr_y-1)),\n",
    "            [train_size, val_size]\n",
    "        )\n",
    "    \n",
    "        test_ds = torch.utils.data.TensorDataset(torch.from_numpy(te_x), torch.from_numpy(te_y-1))\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_ds, batch_size=self.batch_size)\n",
    "    \n",
    "        best_loss = float('inf')\n",
    "        for e in range(self.n_epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            train_loader = torch.utils.data.DataLoader(train_ds, batch_size=self.batch_size, shuffle=True)\n",
    "            \n",
    "            # Initialize training metrics\n",
    "            epoch_train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            # Start timing and memory tracking\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.cuda().float(), yb.cuda().long()\n",
    "                aug_x, aug_y = self.interaug(tr_x, tr_y)\n",
    "                xb = torch.cat([xb, aug_x])\n",
    "                yb = torch.cat([yb, aug_y])\n",
    "                \n",
    "                _, out = self.model(xb)\n",
    "                loss = self.criterion(out, yb)\n",
    "                \n",
    "                # Backprop\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Track metrics\n",
    "                epoch_train_loss += loss.item()\n",
    "                preds = out.argmax(dim=1)\n",
    "                train_correct += (preds == yb).sum().item()\n",
    "                total_samples += yb.size(0)\n",
    "    \n",
    "            # Calculate training metrics\n",
    "            train_loss = epoch_train_loss / len(train_loader)\n",
    "            train_acc = train_correct / total_samples\n",
    "            \n",
    "            # Calculate memory and speed\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed = time.time() - start_time\n",
    "            mem_used = torch.cuda.max_memory_allocated() / (1024 ** 2)  # MB\n",
    "            speed = total_samples / elapsed if elapsed > 0 else 0\n",
    "    \n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            with torch.no_grad():\n",
    "                val_loader = torch.utils.data.DataLoader(val_ds, batch_size=self.batch_size)\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.cuda().float(), yb.cuda().long()\n",
    "                    _, out = self.model(xb)\n",
    "                    loss = self.criterion(out, yb)\n",
    "                    val_loss += loss.item()\n",
    "                    val_correct += (out.argmax(1) == yb).sum().item()\n",
    "    \n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_acc = val_correct / len(val_ds)\n",
    "    \n",
    "            print(f\"Epoch {e+1}/{self.n_epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | \"\n",
    "                  f\"Mem: {mem_used:.2f}MB | Speed: {speed:.2f} samples/s\")\n",
    "    \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), self.model_filename)\n",
    "            else:\n",
    "                self.no_improve += 1\n",
    "                if self.no_improve >= self.patience:\n",
    "                    print(f\"Stopping early at epoch {e+1} (no improvement in {self.patience} epochs).\")\n",
    "                    break\n",
    "\n",
    "    # Rest of test evaluation...\n",
    "\n",
    "    # Rest of test evaluation remains the same...\n",
    "\n",
    "        self.model.load_state_dict(torch.load(self.model_filename))\n",
    "        self.model.eval()\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in self.test_loader:\n",
    "                xb = xb.cuda()\n",
    "                _, out = self.model(xb)\n",
    "                preds.append(out.argmax(1).cpu().numpy())\n",
    "                trues.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); trues = np.concatenate(trues)\n",
    "        acc, *_ = calMetrics(trues, preds)\n",
    "        print(f\"Subject {self.nSub} final accuracy: {acc:.4f}\")\n",
    "        return acc\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "def main(result_dir, DATA_DIR, N_SUBJECT, **cfg):\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    number_class, number_channel = numberClassChannel(cfg['dataset_type'])\n",
    "    model = EEGMambaTransformer(\n",
    "        emb_size=cfg['emb_size'], depth=cfg['depth'], heads=cfg['heads'],\n",
    "        d_state=cfg['d_state'],\n",
    "        transformer_depth=cfg['transformer_depth'],\n",
    "        mamba_depth=cfg['mamba_depth'],\n",
    "        database_type=cfg['dataset_type'],\n",
    "        eeg1_f1=cfg['eeg1_f1'], eeg1_kernel_size=cfg['eeg1_kernel_size'],\n",
    "        eeg1_D=cfg['eeg1_D'], eeg1_pooling_size1=cfg['eeg1_pooling_size1'],\n",
    "        eeg1_pooling_size2=cfg['eeg1_pooling_size2'],\n",
    "        eeg1_dropout_rate=cfg['eeg1_dropout_rate'],\n",
    "        flatten_eeg1=cfg['flatten_eeg1']\n",
    "    ).cuda()\n",
    "    summary(model, (1, number_channel, 1000))\n",
    "    print(time.asctime(time.localtime(time.time())))\n",
    "\n",
    "    accs = []\n",
    "    for sub in range(1, N_SUBJECT+1):\n",
    "        seed_n = np.random.randint(2024)\n",
    "        random.seed(seed_n); np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n); torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "        print(f\"seed is {seed_n}\")\n",
    "        print(f\"Subject {sub}\")\n",
    "\n",
    "        exp = ExP(sub, DATA_DIR, result_dir, **cfg)\n",
    "        accs.append(exp.train())\n",
    "\n",
    "    print(\"Average accuracy:\", np.mean(accs))\n",
    "    return accs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "    CONFIG = dict(\n",
    "        emb_size=256, depth=1, heads=4,\n",
    "        d_state=64, transformer_depth=1, mamba_depth=2,\n",
    "        dataset_type='A',\n",
    "        eeg1_f1=8, eeg1_kernel_size=64,\n",
    "        eeg1_D=32, eeg1_pooling_size1=8, eeg1_pooling_size2=8,\n",
    "        eeg1_dropout_rate=0.6, flatten_eeg1=15*256,\n",
    "        epochs=1000, number_aug=3, number_seg=8,\n",
    "        validate_ratio=0.3, learning_rate=1e-3, batch_size=36\n",
    "    )\n",
    "\n",
    "    DATA_DIR   = \"bci2a/\"\n",
    "    RESULT_DIR = f\"CTNet_Mamba_{int(time.time())}\"\n",
    "    N_SUBJECT  = 9\n",
    "\n",
    "    main(RESULT_DIR, DATA_DIR, N_SUBJECT, **CONFIG)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c0af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: torch.Size([1, 1, 22, 1000])\n",
      "Output data shape after CNN: torch.Size([1, 15, 16])\n",
      "tensor([[[ 4.4427e-02,  1.6865e-01,  0.0000e+00,  4.4497e-01,  1.6248e-01,\n",
      "           2.2551e-02,  2.1011e-01,  1.3673e-01,  7.4656e-01,  5.7626e-01,\n",
      "           0.0000e+00, -0.0000e+00,  2.6901e-01,  6.1869e-01,  5.1004e-01,\n",
      "           1.1605e-01],\n",
      "         [ 3.4188e-01, -2.1637e-01,  9.2026e-02,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  9.8942e-01, -0.0000e+00, -6.7854e-01,  6.5418e-01,\n",
      "           7.0507e-01,  3.0271e-01,  1.4244e-02, -0.0000e+00,  1.9596e-01,\n",
      "          -0.0000e+00],\n",
      "         [-2.0928e-01,  4.5755e-01,  3.6308e-01,  6.7305e-01,  3.4740e-01,\n",
      "          -3.2171e-01, -4.9382e-01,  2.3126e-01, -2.5969e-01,  9.1415e-02,\n",
      "           1.4810e-01,  6.9497e-01,  6.7038e-01,  2.3976e-01, -6.3225e-01,\n",
      "           0.0000e+00],\n",
      "         [ 7.4252e-01,  1.6591e-02,  0.0000e+00,  4.3490e-02, -4.5228e-02,\n",
      "           1.0913e-01, -4.7366e-01,  6.4331e-01,  0.0000e+00, -2.3919e-01,\n",
      "           0.0000e+00, -0.0000e+00, -1.4047e-02,  7.9586e-01,  9.2566e-01,\n",
      "          -4.2703e-01],\n",
      "         [ 3.7043e-01,  0.0000e+00,  0.0000e+00, -5.6545e-01, -1.1110e-02,\n",
      "           0.0000e+00,  0.0000e+00, -1.3214e-01,  5.7492e-02,  1.3171e-01,\n",
      "           4.2030e-01, -3.8621e-01,  3.2840e-01, -1.1818e-02,  1.2518e+00,\n",
      "          -4.0951e-01],\n",
      "         [ 0.0000e+00,  3.8809e-01,  8.0600e-01,  1.1475e+00,  6.8643e-01,\n",
      "           0.0000e+00,  6.8363e-01,  6.7473e-01, -2.4025e-01, -0.0000e+00,\n",
      "           2.0243e-01,  0.0000e+00,  2.6589e-01, -3.5136e-01, -0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-8.5594e-02,  1.3009e+00, -0.0000e+00,  1.1982e-01,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00,  8.8374e-02,  6.6964e-01,  1.4442e-01,\n",
      "           5.5992e-02,  8.8978e-01,  0.0000e+00,  5.4861e-01, -8.8938e-02,\n",
      "           5.9302e-01],\n",
      "         [ 5.4211e-01,  9.2589e-02,  0.0000e+00,  8.7419e-02,  2.8512e-01,\n",
      "           7.8405e-01, -0.0000e+00,  0.0000e+00,  4.1744e-01,  0.0000e+00,\n",
      "          -1.4409e-01, -0.0000e+00,  0.0000e+00,  5.6530e-01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 3.2527e-01, -5.1926e-01,  0.0000e+00, -1.8896e-01, -1.1162e-01,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00, -7.2114e-02,  0.0000e+00,\n",
      "           1.1083e+00,  0.0000e+00, -0.0000e+00, -3.4631e-01,  5.8129e-01,\n",
      "           3.1251e-01],\n",
      "         [ 2.7661e-01, -9.9311e-02,  4.5080e-01,  6.7687e-01,  7.3628e-02,\n",
      "           1.0514e-01,  0.0000e+00,  0.0000e+00, -4.1557e-02,  9.6706e-01,\n",
      "          -2.6690e-01,  8.4824e-01,  6.0118e-01,  0.0000e+00, -2.3089e-01,\n",
      "          -1.0114e-01],\n",
      "         [ 1.0573e-01, -6.0879e-02,  1.7781e-01,  9.8409e-01,  7.8010e-01,\n",
      "           1.3277e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "           4.6224e-01,  8.9239e-01,  1.5423e-01,  2.0794e-01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 1.8493e-01,  9.4589e-01,  3.1826e-01,  0.0000e+00,  1.3466e-01,\n",
      "           1.0003e+00,  2.3330e-01,  1.3794e-01,  7.4654e-01, -2.4623e-01,\n",
      "          -4.6275e-01,  3.4397e-01,  2.3859e-01, -2.4864e-01,  0.0000e+00,\n",
      "          -1.2307e-01],\n",
      "         [ 1.0875e+00, -1.1673e-01,  4.0609e-01, -7.5421e-01, -1.0037e-01,\n",
      "          -1.8055e-02,  0.0000e+00,  7.9928e-01,  0.0000e+00,  0.0000e+00,\n",
      "          -1.7958e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,  3.4741e-01,\n",
      "           1.2399e+00],\n",
      "         [-5.3408e-01,  0.0000e+00,  2.5301e-02,  1.5062e-01, -9.7857e-02,\n",
      "          -4.8223e-01,  4.2994e-01,  2.6422e-02,  4.5894e-01, -0.0000e+00,\n",
      "           5.0923e-01,  2.4965e-01,  0.0000e+00, -1.3838e-01,  2.7507e-01,\n",
      "           7.1254e-01],\n",
      "         [ 3.9812e-02,  1.0217e+00,  0.0000e+00,  0.0000e+00,  6.9760e-01,\n",
      "          -0.0000e+00, -2.4237e-01,  6.6910e-01,  6.9332e-01, -1.0611e-01,\n",
      "           4.6187e-01, -9.7687e-04,  2.9560e-01,  0.0000e+00, -4.2912e-01,\n",
      "           0.0000e+00]]], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the CNN model\n",
    "class PatchEmbeddingCNN(nn.Module):\n",
    "    def __init__(self, f1=16, kernel_size=64, D=2, pooling_size1=8, pooling_size2=8, dropout_rate=0.3, number_channel=22, emb_size=40):\n",
    "        super().__init__()\n",
    "        f2 = D * f1\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            # Temporal convolution (kernel size = 64)\n",
    "            nn.Conv2d(1, f1, (1, kernel_size), (1, 1), padding='same', bias=False), # [batch, 1, 22, 1000]\n",
    "            nn.BatchNorm2d(f1),\n",
    "            # Channel depth-wise convolution\n",
    "            nn.Conv2d(f1, f2, (number_channel, 1), (1, 1), groups=f1, padding='valid', bias=False), \n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            # Average pooling to obtain 'patches' along the time dimension (as in ViT)\n",
    "            nn.AvgPool2d((1, pooling_size1)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            # Additional spatial convolution\n",
    "            nn.Conv2d(f2, f2, (1, 16), padding='same', bias=False), \n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            # Final pooling\n",
    "            nn.AvgPool2d((1, pooling_size2)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "        # Projection to reshape the tensor to match the desired output format\n",
    "        self.projection = nn.Sequential(\n",
    "            Rearrange('b e h w -> b (h w) e'),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.cnn_module(x)  # Pass through CNN layers\n",
    "        x = self.projection(x)   # Flatten and rearrange to (batch, seq_len, emb_size)\n",
    "        return x\n",
    "\n",
    "# Create a dummy input tensor (example: 288 samples, 1 channel, 22 features, 1000 time steps)\n",
    "input_data = torch.randn(1, 1, 22, 1000)  # Random example data\n",
    "\n",
    "# Initialize the CNN model\n",
    "cnn_model = PatchEmbeddingCNN(f1=8, kernel_size=64, D=2, pooling_size1=8, pooling_size2=8, dropout_rate=0.3, number_channel=22, emb_size=40)\n",
    "\n",
    "# Pass the input data through the CNN model\n",
    "output_data = cnn_model(input_data)\n",
    "\n",
    "# Print the shape of the output data\n",
    "print(f\"Input data shape: {input_data.shape}\")\n",
    "print(f\"Output data shape after CNN: {output_data.shape}\")\n",
    "print(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1f72b7-6945-48be-9251-3d4b1233790a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2890110464"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5873853d-4e62-4886-9f2f-137de970b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15, 16, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mamba_transformer import MambaTransformer\n",
    "# Create an instance of the MambaTransformer model\n",
    "model = MambaTransformer(\n",
    "    num_tokens=100,  # Number of tokens in the input sequence\n",
    "    dim=512,  # Dimension of the model\n",
    "    heads=8,  # Number of attention heads\n",
    "    depth=4,  # Number of transformer layers\n",
    "    dim_head=64,  # Dimension of each attention head\n",
    "    d_state=512,  # Dimension of the state\n",
    "    dropout=0.1,  # Dropout rate\n",
    "    ff_mult=4,  # Multiplier for the feed-forward layer dimension\n",
    "    return_embeddings=False,  # Whether to return the embeddings,\n",
    "    transformer_depth=2,  # Number of transformer blocks\n",
    "    mamba_depth=10,  # Number of Mamba blocks,\n",
    "    use_linear_attn=True,  # Whether to use linear attention\n",
    ")\n",
    "\n",
    "# Pass the input tensor through the model and print the output shape\n",
    "output_data = output_data.long()  # Convert the tensor to Long type\n",
    "\n",
    "out = model(output_data)\n",
    "\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
