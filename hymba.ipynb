{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec370bd9-dfb5-4b70-ad80-4b6d38d5b6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Monkey-patch MultiheadAttention so forward() returns only `attn_output`\n",
    "# -------------------------------------------------------------------------\n",
    "_original_mha_forward = nn.MultiheadAttention.forward\n",
    "\n",
    "def _mha_forward_no_weights(self, query, key, value, *args, **kwargs):\n",
    "    # call the original, then discard the weights\n",
    "    attn_output, _ = _original_mha_forward(self, query, key, value, *args, **kwargs)\n",
    "    return attn_output\n",
    "\n",
    "nn.MultiheadAttention.forward = _mha_forward_no_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62de866c-109e-468c-a9b1-5da1f5c059c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartview/miniconda3/envs/vim_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m log_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhymbaprinted.log\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Redirect stdout (print, summary, etc.)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(log_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout  \u001b[38;5;66;03m# Optional: log errors too\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# PatchEmbeddingCNN\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "CTNet-Mamba: A Convolution-Mamba Network for EEG-Based Motor Imagery Classification\n",
    "\n",
    "author: zhaowei701@163.com\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from barebones_hymba.barebones_hymba_block import HymbaBlock\n",
    "import flash_attn\n",
    "\n",
    "import numpy as np\n",
    "from zeta.nn import MultiQueryAttention\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.backends import cudnn\n",
    "from torchsummary import summary\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from utils import load_data_evaluate, numberClassChannel, calMetrics\n",
    "\n",
    "# Try to import real MambaBlock (fallback if missing)\n",
    "try:\n",
    "    from mamba_ssm import Mamba\n",
    "except ImportError:\n",
    "    class Mamba(nn.Module):\n",
    "        def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "            super().__init__()\n",
    "            self.linear = nn.Linear(d_model, d_model)\n",
    "        def forward(self, x):\n",
    "            return self.linear(x)\n",
    "\n",
    "from zeta.nn import MambaBlock, FeedForward, MultiQueryAttention\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PatchEmbeddingCNN\n",
    "# -----------------------------------------------------------------------------\n",
    "class PatchEmbeddingCNN(nn.Module):\n",
    "    def __init__(self, f1=16, kernel_size=64, D=2,\n",
    "                 pooling_size1=8, pooling_size2=8,\n",
    "                 dropout_rate=0.3, number_channel=22, emb_size=40):\n",
    "        super().__init__()\n",
    "        f2 = D * f1\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, (1, kernel_size), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.Conv2d(f1, f2, (number_channel, 1), groups=f1, bias=False),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pooling_size1)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(f2, f2, (1, 16), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pooling_size2)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.projection = Rearrange('b e h w -> b (h w) e')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_module(x)        # [B, f2, 1, seq]\n",
    "        return self.projection(x)     # [B, seq, f2]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# LinearAttention\n",
    "# -----------------------------------------------------------------------------\n",
    "def exists(val): return val is not None\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, *, heads=4, dim_head=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        inner = heads * dim_head\n",
    "        self.heads, self.scale = heads, dim_head**-0.5\n",
    "        self.to_qkv = nn.Linear(dim, inner*3, bias=False)\n",
    "        self.to_out = nn.Sequential(nn.Linear(inner, dim), nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        h = self.heads\n",
    "        q,k,v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q,k,v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=h), (q,k,v))\n",
    "        q, k = q*self.scale, k\n",
    "        q, k = q.softmax(dim=-1), k.softmax(dim=-2)\n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, 'b n -> (b h) n', h=h)\n",
    "            k = k.masked_fill(~mask.unsqueeze(-1), 0.)\n",
    "        ctx = torch.einsum('b n d, b n e -> b d e', q, k)\n",
    "        out = torch.einsum('b d e, b n d -> b n e', ctx, v)\n",
    "        out = rearrange(out, '(b h) n d -> b n (h d)', h=h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TransformerBlock\n",
    "# -----------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MambaTransformerblock(nn.Module):\n",
    "    def __init__(self, dim, heads, dim_head, dropout=0.1, \n",
    "                 ff_mult=4, d_state=16, depth=4):        \n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            self._create_layer(dim, heads, ff_mult, d_state, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def _create_layer(self, dim, heads, ff_mult, d_state, dropout):\n",
    "        return nn.ModuleDict({\n",
    "            # 1) Mamba\n",
    "            'mamba_norm':   nn.LayerNorm(dim),\n",
    "            'mamba':        MambaBlock(dim, d_state=d_state),\n",
    "            'mamba_dropout':nn.Dropout(dropout),\n",
    "\n",
    "            # 2) PyTorch MultiheadAttention\n",
    "            'attn_norm':    nn.LayerNorm(dim),\n",
    "            'attn':         nn.MultiheadAttention(embed_dim=dim,\n",
    "                                                  num_heads=heads,\n",
    "                                                  dropout=dropout,\n",
    "                                                  batch_first=True),\n",
    "            'attn_dropout': nn.Dropout(dropout),\n",
    "\n",
    "            # 3) FFN\n",
    "            'ffn_norm':     nn.LayerNorm(dim),\n",
    "            'feedforward':  nn.Sequential(\n",
    "                                 nn.Linear(dim, ff_mult * dim),\n",
    "                                 nn.GELU(),\n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(ff_mult * dim, dim)\n",
    "                             ),\n",
    "            'ffn_dropout':  nn.Dropout(dropout),\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, dim]\n",
    "        for layer in self.layers:\n",
    "            # (1) Mamba sublayer\n",
    "            m = layer['mamba_norm'](x)\n",
    "            x = x + layer['mamba_dropout'](layer['mamba'](m))\n",
    "\n",
    "            # (2) Multi-head self-attention sublayer\n",
    "            a = layer['attn_norm'](x)\n",
    "            # because of the monkey-patch, this returns a Tensor directly\n",
    "            attn_out = layer['attn'](a, a, a, need_weights=False)\n",
    "            x = x + layer['attn_dropout'](attn_out)\n",
    "\n",
    "            # (3) Feed-forward sublayer\n",
    "            f = layer['ffn_norm'](x)\n",
    "            x = x + layer['ffn_dropout'](layer['feedforward'](f))\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "\n",
    "class SummaryWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [B, C, T] âžœ [B, 1, C, T]\n",
    "        _, out = self.model(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# EEGMambaTransformer\n",
    "# -----------------------------------------------------------------------------\n",
    "class EEGMambaTransformer(nn.Module):\n",
    "    def __init__(self, emb_size=40, depth=6, heads=4,\n",
    "                 d_state=16, transformer_depth=1, mamba_depth=3,\n",
    "                 database_type='A', eeg1_f1=8, eeg1_kernel_size=64,\n",
    "                 eeg1_D=2, eeg1_pooling_size1=8, eeg1_pooling_size2=8,\n",
    "                 eeg1_dropout_rate=0.5, flatten_eeg1=15*16):\n",
    "        super().__init__()\n",
    "        self.number_class, self.number_channel = numberClassChannel(database_type)\n",
    "        self.norm = nn.LayerNorm(emb_size)\n",
    "\n",
    "        self.cnn = PatchEmbeddingCNN(\n",
    "            f1=eeg1_f1, kernel_size=eeg1_kernel_size,\n",
    "            D=eeg1_D, pooling_size1=eeg1_pooling_size1,\n",
    "            pooling_size2=eeg1_pooling_size2,\n",
    "            dropout_rate=eeg1_dropout_rate,\n",
    "            number_channel=self.number_channel,\n",
    "            emb_size=emb_size\n",
    "        )\n",
    "\n",
    "        dim_head = emb_size // heads\n",
    "        self.hymba_layers = nn.ModuleList([\n",
    "            HymbaBlock(\n",
    "                mamba_expand=2,         # how much Mamba expands hidden dim\n",
    "                hidden_size=emb_size,             # model hidden dimension\n",
    "                num_attention_heads=heads,         # full attention heads\n",
    "                num_key_value_heads=max(1, heads//2),\n",
    "                conv_kernel_size=3,\n",
    "                time_step_rank=d_state,            # SSM state dimension\n",
    "                ssm_state_size=d_state,            # SSM state dimension\n",
    "                attention_window_size=64,\n",
    "                modify_attention_mask=False,\n",
    "                num_meta_tokens=0,\n",
    "                seq_length=15,\n",
    "                use_positional_embedding=True,\n",
    "                rope_base=10000,\n",
    "            )\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        self.mamba_transformer = MambaTransformerblock(\n",
    "            dim=emb_size, heads=heads,\n",
    "            dim_head=dim_head,\n",
    "            dropout=eeg1_dropout_rate, ff_mult=4,\n",
    "            d_state=d_state,\n",
    "            depth = depth,\n",
    "        )\n",
    "        self.drouput = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(flatten_eeg1, self.number_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)                       # [B, seq, emb]\n",
    "        x = x * math.sqrt(x.shape[-1])\n",
    "\n",
    "        for block in self.hymba_layers:\n",
    "            x = block(x)                     # hybrid SSM + attention\n",
    "        return x, self.classification(self.flatten(x))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Experiment wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "class ExP:\n",
    "    def __init__(self, nsub, data_dir, result_name,\n",
    "                 epochs=300, number_aug=3, number_seg=8,\n",
    "                 evaluate_mode='subject-dependent',\n",
    "                 heads=2, emb_size=16, depth=6,\n",
    "                 d_state=16, transformer_depth=1, mamba_depth=3,\n",
    "                 dataset_type='A', eeg1_f1=8, eeg1_kernel_size=64,\n",
    "                 eeg1_D=2, eeg1_pooling_size1=8, eeg1_pooling_size2=8,\n",
    "                 eeg1_dropout_rate=0.5, flatten_eeg1=15*16,\n",
    "                 validate_ratio=0.3, learning_rate=1e-3, batch_size=72,\n",
    "                 early_stopping_patience=100 ):\n",
    "        self.nSub = nsub\n",
    "        self.dataset_type = dataset_type\n",
    "        self.data_dir = data_dir\n",
    "        self.result_name = result_name\n",
    "        self.n_epochs = epochs\n",
    "        self.patience = early_stopping_patience\n",
    "        self.no_improve = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.batch_size = batch_size\n",
    "        self.validate_ratio = validate_ratio\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        self.model = EEGMambaTransformer(\n",
    "            emb_size=emb_size, depth=depth, heads=heads,\n",
    "            d_state=d_state,\n",
    "            transformer_depth=transformer_depth,\n",
    "            mamba_depth=mamba_depth,\n",
    "            database_type=dataset_type,\n",
    "            eeg1_f1=eeg1_f1, eeg1_kernel_size=eeg1_kernel_size,\n",
    "            eeg1_D=eeg1_D, eeg1_pooling_size1=eeg1_pooling_size1,\n",
    "            eeg1_pooling_size2=eeg1_pooling_size2,\n",
    "            eeg1_dropout_rate=eeg1_dropout_rate,\n",
    "            flatten_eeg1=flatten_eeg1\n",
    "        ).cuda()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        os.makedirs(self.result_name, exist_ok=True)\n",
    "        self.model_filename = os.path.join(self.result_name, f\"model_{self.nSub}.pth\")\n",
    "\n",
    "    def interaug(self, timg, label):\n",
    "        aug_data, aug_label = [], []\n",
    "        recs = 3 * (self.batch_size // self.model.number_class)\n",
    "        segpts = 1000 // 8\n",
    "        for cls in range(self.model.number_class):\n",
    "            idx = np.where(label == cls + 1)\n",
    "            data, lbl = timg[idx], label[idx]\n",
    "            tmp = np.zeros((recs,1,self.model.number_channel,1000), dtype=np.float32)\n",
    "            for i in range(recs):\n",
    "                for j in range(8):\n",
    "                    ridx = random.randrange(data.shape[0])\n",
    "                    tmp[i,0,:,j*segpts:(j+1)*segpts] = data[ridx,0,:,j*segpts:(j+1)*segpts]\n",
    "            aug_data.append(tmp); aug_label.append(lbl[:recs])\n",
    "        aug_data = np.concatenate(aug_data).astype(np.float32)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        perm = np.random.permutation(len(aug_data))\n",
    "        return (\n",
    "            torch.from_numpy(aug_data[perm]).cuda(),\n",
    "            torch.from_numpy((aug_label[perm]-1)).long().cuda()\n",
    "        )\n",
    "\n",
    "    def get_source_data(self):\n",
    "        tr_x, tr_y, te_x, te_y = load_data_evaluate(\n",
    "            self.data_dir, self.dataset_type, self.nSub,\n",
    "            mode_evaluate='subject-dependent'\n",
    "        )\n",
    "        tr_x = np.expand_dims(tr_x, axis=1).astype(np.float32)\n",
    "        te_x = np.expand_dims(te_x, axis=1).astype(np.float32)\n",
    "        tr_y = tr_y.reshape(-1)\n",
    "        te_y = te_y.reshape(-1)\n",
    "        m, s = tr_x.mean(), tr_x.std()\n",
    "        tr_x = (tr_x - m) / s\n",
    "        te_x = (te_x - m) / s\n",
    "        return tr_x, tr_y, te_x, te_y\n",
    "\n",
    "    def train(self):\n",
    "        tr_x, tr_y, te_x, te_y = self.get_source_data()\n",
    "    \n",
    "        # Create validation split\n",
    "        dataset_size = len(tr_x)\n",
    "        val_size = int(self.validate_ratio * dataset_size)\n",
    "        train_size = dataset_size - val_size\n",
    "        train_ds, val_ds = torch.utils.data.random_split(\n",
    "            torch.utils.data.TensorDataset(torch.from_numpy(tr_x), torch.from_numpy(tr_y-1)),\n",
    "            [train_size, val_size]\n",
    "        )\n",
    "    \n",
    "        test_ds = torch.utils.data.TensorDataset(torch.from_numpy(te_x), torch.from_numpy(te_y-1))\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_ds, batch_size=self.batch_size)\n",
    "    \n",
    "        best_loss = float('inf')\n",
    "        for e in range(self.n_epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            train_loader = torch.utils.data.DataLoader(train_ds, batch_size=self.batch_size, shuffle=True)\n",
    "            \n",
    "            # Initialize training metrics\n",
    "            epoch_train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            # Start timing and memory tracking\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.cuda().float(), yb.cuda().long()\n",
    "                aug_x, aug_y = self.interaug(tr_x, tr_y)\n",
    "                xb = torch.cat([xb, aug_x])\n",
    "                yb = torch.cat([yb, aug_y])\n",
    "                \n",
    "                _, out = self.model(xb)\n",
    "                loss = self.criterion(out, yb)\n",
    "                \n",
    "                # Backprop\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Track metrics\n",
    "                epoch_train_loss += loss.item()\n",
    "                preds = out.argmax(dim=1)\n",
    "                train_correct += (preds == yb).sum().item()\n",
    "                total_samples += yb.size(0)\n",
    "    \n",
    "            # Calculate training metrics\n",
    "            train_loss = epoch_train_loss / len(train_loader)\n",
    "            train_acc = train_correct / total_samples\n",
    "            \n",
    "            # Calculate memory and speed\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed = time.time() - start_time\n",
    "            mem_used = torch.cuda.max_memory_allocated() / (1024 ** 2)  # MB\n",
    "            speed = total_samples / elapsed if elapsed > 0 else 0\n",
    "    \n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            with torch.no_grad():\n",
    "                val_loader = torch.utils.data.DataLoader(val_ds, batch_size=self.batch_size)\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.cuda().float(), yb.cuda().long()\n",
    "                    _, out = self.model(xb)\n",
    "                    loss = self.criterion(out, yb)\n",
    "                    val_loss += loss.item()\n",
    "                    val_correct += (out.argmax(1) == yb).sum().item()\n",
    "    \n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_acc = val_correct / len(val_ds)\n",
    "    \n",
    "            print(f\"Epoch {e+1}/{self.n_epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | \"\n",
    "                  f\"Mem: {mem_used:.2f}MB | Speed: {speed:.2f} samples/s\")\n",
    "    \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), self.model_filename)\n",
    "\n",
    "\n",
    "    # Rest of test evaluation...\n",
    "\n",
    "    # Rest of test evaluation remains the same...\n",
    "\n",
    "        self.model.load_state_dict(torch.load(self.model_filename))\n",
    "        self.model.eval()\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in self.test_loader:\n",
    "                xb = xb.cuda()\n",
    "                _, out = self.model(xb)\n",
    "                preds.append(out.argmax(1).cpu().numpy())\n",
    "                trues.append(yb.numpy())\n",
    "        preds = np.concatenate(preds); trues = np.concatenate(trues)\n",
    "        acc, *_ = calMetrics(trues, preds)\n",
    "        print(f\"Subject {self.nSub} final accuracy: {acc:.4f}\")\n",
    "        return acc\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "def main(result_dir, DATA_DIR, N_SUBJECT, **cfg):\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    number_class, number_channel = numberClassChannel(cfg['dataset_type'])\n",
    "    model = EEGMambaTransformer(\n",
    "        emb_size=cfg['emb_size'], depth=cfg['depth'], heads=cfg['heads'],\n",
    "        d_state=cfg['d_state'],\n",
    "        transformer_depth=cfg['transformer_depth'],\n",
    "        mamba_depth=cfg['mamba_depth'],\n",
    "        database_type=cfg['dataset_type'],\n",
    "        eeg1_f1=cfg['eeg1_f1'], eeg1_kernel_size=cfg['eeg1_kernel_size'],\n",
    "        eeg1_D=cfg['eeg1_D'], eeg1_pooling_size1=cfg['eeg1_pooling_size1'],\n",
    "        eeg1_pooling_size2=cfg['eeg1_pooling_size2'],\n",
    "        eeg1_dropout_rate=cfg['eeg1_dropout_rate'],\n",
    "        flatten_eeg1=cfg['flatten_eeg1']\n",
    "    ).cuda()\n",
    "\n",
    "    summary(\n",
    "        model, \n",
    "        input_size=(1, 1, number_channel, 1000),  # batch, channel=1, EEG channels, time\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        depth=3,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "    print(time.asctime(time.localtime(time.time())))\n",
    "\n",
    "    accs = []\n",
    "    for sub in range(1, N_SUBJECT+1):\n",
    "        seed_n = np.random.randint(2024)\n",
    "        random.seed(seed_n); np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n); torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "        print(f\"seed is {seed_n}\")\n",
    "        print(f\"Subject {sub}\")\n",
    "\n",
    "        exp = ExP(sub, DATA_DIR, result_dir, **cfg)\n",
    "        accs.append(exp.train())\n",
    "\n",
    "    print(\"Average accuracy:\", np.mean(accs))\n",
    "    return accs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "    CONFIG = dict(\n",
    "        emb_size=128, depth=1, heads=4,\n",
    "        d_state=32, transformer_depth=1, mamba_depth=2,\n",
    "        dataset_type='A',\n",
    "        eeg1_f1=8, eeg1_kernel_size=64,\n",
    "        eeg1_D=16, eeg1_pooling_size1=8, eeg1_pooling_size2=8,\n",
    "        eeg1_dropout_rate=0.5, flatten_eeg1=15*128,\n",
    "        epochs=1000, number_aug=3, number_seg=8,\n",
    "        validate_ratio=0.3, learning_rate=1e-3, batch_size=72\n",
    "    )\n",
    "\n",
    "    DATA_DIR   = \"bci2a/\"\n",
    "    RESULT_DIR = f\"CTNet_Mamba_{int(time.time())}\"\n",
    "    N_SUBJECT  = 9\n",
    "\n",
    "    main(RESULT_DIR, DATA_DIR, N_SUBJECT, **CONFIG)\n",
    "    print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vim_env)",
   "language": "python",
   "name": "vim_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
